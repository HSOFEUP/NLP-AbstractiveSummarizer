{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty, eos, maxlend, maxlenh, maxlen, seed = 0,1, 25, 10, 35, 42\n",
    "\n",
    "activation_rnn_size = 40 if maxlend else 0\n",
    "nb_unknown_words = 10\n",
    "\n",
    "# function names\n",
    "FN0 = 'vocabulary-embedding'  # filename of vocab embeddings\n",
    "FN1 = 'train'  # filename of model weights\n",
    "\n",
    "# training variables\n",
    "seed = 42\n",
    "optimizer = 'adam'\n",
    "p_W, p_U, p_dense, p_emb, weight_decay = 0, 0, 0, 0, 0\n",
    "regularizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rajsu\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.article.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-55efc8a0ffa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesc_data_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0mdesc_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhead_data_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.article.txt'"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "import _pickle as pickle\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import _pickle as pickle\n",
    "from os import path\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Lambda\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "desc_data_loc = \"train.article.txt\"\n",
    "head_data_loc = \"train.title.txt\"\n",
    "\n",
    "\n",
    "with open(desc_data_loc, 'r', encoding='utf-8') as f:\n",
    "    desc_lines = f.read().split('\\n')\n",
    "with open(head_data_loc, 'r', encoding='utf-8') as f:\n",
    "    head_lines = f.read().split('\\n')\n",
    "    \n",
    "X_data, Y_data = [],[]\n",
    "for i in range(len(desc_lines)):\n",
    "    if( len(desc_lines[i].split()) <= maxlend and len(head_lines[i].split()) <= maxlenh-1 ):\n",
    "        X_data.append(desc_lines[i].lower())\n",
    "        Y_data.append(head_lines[i].lower())\n",
    "print(len(X_data))\n",
    "\n",
    "\n",
    "with open('tokens.pkl', 'wb') as fp:\n",
    "            pickle.dump((Y_data[:500000],X_data[:500000]), fp, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular tokens:\n",
      "['.', 'the', 'in', 'a', 'to', ',', 'of', 'on', \"'s\", 'for', 'and', 'said', 'at', '<unk>', 'with', '##', 'has', 'is', 'as', 'from', 'new', 'an', 'wednesday', 'tuesday', 'thursday', 'after', 'his', 'was', 'friday', 'that', 'monday', 'by', 'percent', 'it', 'its', 'will', 'president', 'against', 'world', 'have', 'two', 'u.s.', 'prices', 'police', 'are', 'saturday', 'over', 'us', 'up', 'sunday']\n",
      "Total vocab size: 90,816\n",
      "400,000 GloVe symbols\n",
      "GloVe std dev: 0.0408\n",
      "random-embedding/glove scale: 0.0707 std: 0.0408\n",
      "number of tokens, in small vocab: 38,633 found in glove and copied to embedding: 0.9658\n",
      "\n",
      "# of GloVe substitutes found: 32,532\n",
      "0.5001 hayne => charvis\n",
      "0.5000 taranath => cagni\n",
      "0.5000 croll => mccrary\n",
      "0.5000 tartus => zaporizhia\n",
      "0.5000 crouse => suggs\n",
      "0.5000 hallett => woolsey\n",
      "0.5000 felcor => accor\n",
      "0.5000 kunin => teter\n",
      "0.5000 osmar => legler\n",
      "0.5000 domenic => dalibor\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Generate intial word embedding for headlines and description.\n",
    "\n",
    "The embedding is limited to a fixed vocabulary size (`vocab_size`) but\n",
    "a vocabulary of all the words that appeared in the data is built.\n",
    "\"\"\"\n",
    "import io\n",
    "\n",
    "# static vars\n",
    "FN = 'vocabulary-embedding'\n",
    "seed = 42\n",
    "vocab_size = 40000\n",
    "embedding_dim = 100\n",
    "lower = False\n",
    "\n",
    "# index words\n",
    "empty = 0  # RNN mask of no data\n",
    "eos = 1  # end of sentence\n",
    "start_idx = eos + 1  # first real word\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "def build_vocab(lst):\n",
    "    \"\"\"Return vocabulary for iterable `lst`.\"\"\"\n",
    "    vocab_count = Counter(w for txt in lst for w in txt.split())\n",
    "    vocab = list(map(lambda x: x[0], sorted(vocab_count.items(), key=lambda x: -x[1])))\n",
    "    return vocab, vocab_count\n",
    "\n",
    "\n",
    "def load_text():\n",
    "    \"\"\"Return vocabulary for pickled headlines and descriptions.\"\"\"\n",
    "    # read tokenized headlines and descriptions\n",
    "    with open('tokens.pkl', 'rb') as fp:\n",
    "        headlines, desc = pickle.load(fp)\n",
    "\n",
    "    # map headlines and descriptions to lower case\n",
    "    if lower:\n",
    "        headlines = [h.lower() for h in headlines]\n",
    "        desc = [h.lower() for h in desc]\n",
    "\n",
    "    return headlines, desc\n",
    "\n",
    "\n",
    "def print_most_popular_tokens(vocab):\n",
    "    \"\"\"Print th most popular tokens in vocabulary dictionary `vocab`.\"\"\"\n",
    "    print('Most popular tokens:')\n",
    "    print(vocab[:50])\n",
    "    print('Total vocab size: {:,}'.format(len(vocab)))\n",
    "\n",
    "'''\n",
    "def plot_word_distributions(vocab, vocab_count):\n",
    "    \"\"\"Plot word distribution in headlines and discription.\"\"\"\n",
    "    plt.plot([vocab_count[w] for w in vocab])\n",
    "    plt.gca().set_xscale(\"log\", nonposx='clip')\n",
    "    plt.gca().set_yscale(\"log\", nonposy='clip')\n",
    "    title = 'word distribution in headlines and discription'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('rank')\n",
    "    plt.ylabel('total appearances')\n",
    "    plt.savefig(path.join(config.path_outputs, '{}.png'.format(title)))\n",
    "'''\n",
    "\n",
    "\n",
    "def get_idx(vocab):\n",
    "    \"\"\"Add empty and end-of-sentence tokens to vocabulary and return tuple (vocabulary, reverse-vocabulary).\"\"\"\n",
    "    word2idx = dict((word, idx + start_idx) for idx, word in enumerate(vocab))\n",
    "    word2idx['<empty>'] = empty\n",
    "    word2idx['<eos>'] = eos\n",
    "    idx2word = dict((idx, word) for word, idx in word2idx.items())\n",
    "    return word2idx, idx2word\n",
    "\n",
    "\n",
    "def get_glove():\n",
    "    \"\"\"Load GloVe embedding weights and indices.\"\"\"\n",
    "    glove_name = 'glove.6B.{}d.txt'.format(embedding_dim)\n",
    "    glove_n_symbols = 0\n",
    "    with io.open(glove_name, encoding=\"utf-8\") as glovedata :\n",
    "        for line in glovedata:\n",
    "            glove_n_symbols+=1\n",
    "    #glove_n_symbols = sum(1 for line in open(glove_name))\n",
    "    print('{:,} GloVe symbols'.format(glove_n_symbols))\n",
    "\n",
    "    # load embedding weights and index dictionary\n",
    "    glove_index_dict = {}\n",
    "    glove_embedding_weights = np.empty((glove_n_symbols, embedding_dim))\n",
    "    globale_scale = .1\n",
    "    with io.open(glove_name, encoding=\"utf-8\") as fp:\n",
    "        i = 0\n",
    "        for l in fp:\n",
    "            l = l.strip().split()\n",
    "            w = l[0]\n",
    "            glove_index_dict[w] = i\n",
    "            glove_embedding_weights[i, :] = list(map(float, l[1:]))\n",
    "            i += 1\n",
    "    glove_embedding_weights *= globale_scale\n",
    "    print('GloVe std dev: {:.4f}'.format(glove_embedding_weights.std()))\n",
    "\n",
    "    # add lower case version of the keys to the dict\n",
    "    for w, i in glove_index_dict.items():\n",
    "        w = w.lower()\n",
    "        if w not in glove_index_dict:\n",
    "            glove_index_dict[w] = i\n",
    "\n",
    "    return glove_embedding_weights, glove_index_dict\n",
    "\n",
    "\n",
    "def initialize_embedding(vocab_size, embedding_dim, glove_embedding_weights):\n",
    "    \"\"\"Use GloVe to initialize random embedding matrix with same scale as glove.\"\"\"\n",
    "    shape = (vocab_size, embedding_dim)\n",
    "    scale = glove_embedding_weights.std() * np.sqrt(12) / 2  # uniform and not normal\n",
    "    embedding = np.random.uniform(low=-scale, high=scale, size=shape)\n",
    "    print('random-embedding/glove scale: {:.4f} std: {:.4f}'.format(scale, embedding.std()))\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def copy_glove_weights(embedding, idx2word, glove_embedding_weights, glove_index_dict):\n",
    "    \"\"\"Copy from glove weights of words that appear in our short vocabulary (idx2word).\"\"\"\n",
    "    c = 0\n",
    "    for i in range(vocab_size):\n",
    "        w = idx2word[i]\n",
    "        g = glove_index_dict.get(w, glove_index_dict.get(w.lower()))\n",
    "        if g is None and w.startswith('#'):  # glove has no hastags (I think...)\n",
    "            w = w[1:]\n",
    "            g = glove_index_dict.get(w, glove_index_dict.get(w.lower()))\n",
    "        if g is not None:\n",
    "            embedding[i, :] = glove_embedding_weights[g, :]\n",
    "            c += 1\n",
    "    print('number of tokens, in small vocab: {:,} found in glove and copied to embedding: {:.4f}'.format(c, c / float(vocab_size)))\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def build_word_to_glove(embedding, word2idx, idx2word, glove_index_dict, glove_embedding_weights):\n",
    "    \"\"\"Map full vocabulary to glove based on cosine distance.\"\"\"\n",
    "    glove_thr = 0.5\n",
    "    word2glove = {}\n",
    "    for w in word2idx:\n",
    "        if w in glove_index_dict:\n",
    "            g = w\n",
    "        elif w.lower() in glove_index_dict:\n",
    "            g = w.lower()\n",
    "        elif w.startswith('#') and w[1:] in glove_index_dict:\n",
    "            g = w[1:]\n",
    "        elif w.startswith('#') and w[1:].lower() in glove_index_dict:\n",
    "            g = w[1:].lower()\n",
    "        else:\n",
    "            continue\n",
    "        word2glove[w] = g\n",
    "\n",
    "    # for every word outside the embedding matrix find the closest word inside the mebedding matrix.\n",
    "    # Use cos distance of GloVe vectors.\n",
    "    # Allow for the last `nb_unknown_words` words inside the embedding matrix to be considered to be outside.\n",
    "    # Dont accept distances below `glove_thr`\n",
    "    normed_embedding = embedding / np.array(\n",
    "        [np.sqrt(np.dot(gweight, gweight)) for gweight in embedding])[:, None]\n",
    "\n",
    "    nb_unknown_words = 100\n",
    "\n",
    "    glove_match = []\n",
    "    for w, idx in word2idx.items():\n",
    "        if idx >= vocab_size - nb_unknown_words and w.isalpha() and w in word2glove:\n",
    "            gidx = glove_index_dict[word2glove[w]]\n",
    "            gweight = glove_embedding_weights[gidx, :].copy()\n",
    "\n",
    "            # find row in embedding that has the highest cos score with gweight\n",
    "            gweight /= np.sqrt(np.dot(gweight, gweight))\n",
    "            score = np.dot(normed_embedding[:vocab_size - nb_unknown_words], gweight)\n",
    "            while True:\n",
    "                embedding_idx = score.argmax()\n",
    "                s = score[embedding_idx]\n",
    "                if s < glove_thr:\n",
    "                    break\n",
    "                if idx2word[embedding_idx] in word2glove:\n",
    "                    glove_match.append((w, embedding_idx, s))\n",
    "                    break\n",
    "                score[embedding_idx] = -1\n",
    "\n",
    "    glove_match.sort(key=lambda x: -x[2])\n",
    "    print()\n",
    "    print('# of GloVe substitutes found: {:,}'.format(len(glove_match)))\n",
    "\n",
    "    # manually check that the worst substitutions we are going to do are good enough\n",
    "    for orig, sub, score in glove_match[-10:]:\n",
    "        print('{:.4f}'.format(score), orig, '=>', idx2word[sub])\n",
    "\n",
    "    # return a lookup table of index of outside words to index of inside words\n",
    "    return dict((word2idx[w], embedding_idx) for w, embedding_idx, _ in glove_match)\n",
    "\n",
    "\n",
    "def to_dense_vector(word2idx, corpus, description, bins=50):\n",
    "    \"\"\"Create a dense vector representation of headlines.\"\"\"\n",
    "    data = [[word2idx[token] for token in txt.split()] for txt in corpus]\n",
    "    #plt.hist(list(map(len, data)), bins=bins)\n",
    "    #plt.savefig(path.join(config.path_outputs, '{}_distribution.png'.format(description)))\n",
    "    return data\n",
    "\n",
    "\n",
    "def summarize_vocab(vocab, vocab_count):\n",
    "    \"\"\"Print the most popular tokens and plot token distributions.\"\"\"\n",
    "    print_most_popular_tokens(vocab)\n",
    "    #plot_word_distributions(vocab, vocab_count)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Generate intial word embedding for headlines and description.\"\"\"\n",
    "    headlines, desc = load_text()  # load headlines and descriptions\n",
    "    vocab, vocab_count = build_vocab(headlines + desc)  # build vocabulary\n",
    "    summarize_vocab(vocab, vocab_count)  # summarize vocabulary\n",
    "    word2idx, idx2word = get_idx(vocab)  # add special tokens and get reverse vocab lookup\n",
    "    glove_embedding_weights, glove_index_dict = get_glove()  # load GloVe data\n",
    "\n",
    "    # initialize embedding\n",
    "    embedding = initialize_embedding(vocab_size, embedding_dim, glove_embedding_weights)\n",
    "    embedding = copy_glove_weights(embedding, idx2word, glove_embedding_weights, glove_index_dict)\n",
    "\n",
    "    # map vocab to GloVe using cosine similarity\n",
    "    glove_idx2idx = build_word_to_glove(embedding, word2idx, idx2word, glove_index_dict, glove_embedding_weights)\n",
    "\n",
    "    # create a dense vector representation of headlines and descriptions\n",
    "    description_vector = to_dense_vector(word2idx, desc, 'description')\n",
    "    headline_vector = to_dense_vector(word2idx, headlines, 'headline')\n",
    "\n",
    "    # write vocabulary to disk\n",
    "    with open('{}.pkl'.format(FN), 'wb') as fp:\n",
    "        pickle.dump((embedding, idx2word, word2idx, glove_idx2idx), fp, 2)\n",
    "\n",
    "    # write data to disk\n",
    "    with open('{}.data.pkl'.format(FN), 'wb') as fp:\n",
    "        pickle.dump((description_vector, headline_vector), fp, 2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpstackoverflowcomquestions295135turn-a-string-into-a-valid-filename\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Utility methods.\"\"\"\n",
    "\n",
    "def join_ingredients(ingredients_listlist):\n",
    "    \"\"\"Join multiple lists of ingredients with ' , '.\"\"\"\n",
    "    return [' , '.join(i) for i in ingredients_listlist]\n",
    "\n",
    "\n",
    "def get_flat_ingredients_list(ingredients_joined_train):\n",
    "    \"\"\"Flatten lists of ingredients encoded as a string into a single list.\"\"\"\n",
    "    return ' , '.join(ingredients_joined_train).split(' , ')\n",
    "\n",
    "\n",
    "def section_print():\n",
    "    \"\"\"Memorized function keeping track of section number.\"\"\"\n",
    "    section_number = 0\n",
    "\n",
    "    def inner(message):\n",
    "        \"\"\"Print section number.\"\"\"\n",
    "        global section_number\n",
    "        section_number += 1\n",
    "        print('Section {}: {}'.format(section_number, message))\n",
    "    print('Section {}: initializing section function'.format(section_number))\n",
    "    return inner\n",
    "\n",
    "\n",
    "def is_filename_char(x):\n",
    "    \"\"\"Return True if x is an acceptable filename character.\"\"\"\n",
    "    if x.isalnum():\n",
    "        return True\n",
    "    if x in ['-', '_']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def url_to_filename(filename):\n",
    "    \"\"\"Map a URL string to filename by removing unacceptable characters.\"\"\"\n",
    "    return \"\".join(x for x in filename if is_filename_char(x))\n",
    "\n",
    "\n",
    "def prt(label, word_idx, idx2word):\n",
    "    \"\"\"Map `word_idx` list to words and print it with its associated `label`.\"\"\"\n",
    "    words = [idx2word[word] for word in word_idx]\n",
    "    print('{}: {}\\n'.format(label, ' '.join(words)))\n",
    "\n",
    "\n",
    "def str_shape(x):\n",
    "    \"\"\"Format the dimension of numpy array `x` as a string.\"\"\"\n",
    "    return 'x'.join([str(element) for element in x.shape])\n",
    "\n",
    "\n",
    "def load_embedding(nb_unknown_words):\n",
    "    \"\"\"Read word embeddings and vocabulary from disk.\"\"\"\n",
    "    with open('{}.pkl'.format(FN0), 'rb') as fp:\n",
    "        embedding, idx2word, word2idx, glove_idx2idx = pickle.load(fp)\n",
    "    vocab_size, embedding_size = embedding.shape\n",
    "    print('dimension of embedding space for words: {:,}'.format(embedding_size))\n",
    "    print('vocabulary size: {:,} the last {:,} words can be used as place holders for unknown/oov words'.\n",
    "          format(vocab_size, nb_unknown_words))\n",
    "    print('total number of different words: {:,}'.format(len(idx2word)))\n",
    "    print('number of words outside vocabulary which we can substitue using glove similarity: {:,}'.\n",
    "          format(len(glove_idx2idx)))\n",
    "    print('number of words that will be regarded as unknonw(unk)/out-of-vocabulary(oov): {:,}'.\n",
    "          format(len(idx2word) - vocab_size - len(glove_idx2idx)))\n",
    "    return embedding, idx2word, word2idx, glove_idx2idx\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Read recipe data from disk.\"\"\"\n",
    "    with open('{}.data.pkl'.format(FN0), 'rb') as fp:\n",
    "        X, Y = pickle.load(fp)\n",
    "    print('number of examples', len(X), len(Y))\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def process_vocab(idx2word, vocab_size, oov0, nb_unknown_words):\n",
    "    \"\"\"Update vocabulary to account for unknown words.\"\"\"\n",
    "    # reserve vocabulary space for unkown words\n",
    "    for i in range(nb_unknown_words):\n",
    "        idx2word[vocab_size - 1 - i] = '<{}>'.format(i)\n",
    "\n",
    "    # mark words outside vocabulary with ^ at their end\n",
    "    for i in range(oov0, len(idx2word)):\n",
    "        idx2word[i] = idx2word[i] + '^'\n",
    "\n",
    "    # add empty word and end-of-sentence to vocab\n",
    "    idx2word[empty] = '_'\n",
    "    idx2word[eos] = '~'\n",
    "\n",
    "    return idx2word\n",
    "\n",
    "\n",
    "def load_split_data(nb_val_samples, seed):\n",
    "    \"\"\"Create train-test split.\"\"\"\n",
    "    # load data and create train test split\n",
    "    X, Y = load_data()\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=nb_val_samples, random_state=seed)\n",
    "    del X, Y  # free up memory by removing X and Y\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(url_to_filename('http://stackoverflow.com/questions/295135/turn-a-string-into-a-valid-filename'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Create an LSTM model for recipe summarization.\"\"\"\n",
    "\n",
    "def inspect_model(model):\n",
    "    \"\"\"Print the structure of Keras `model`.\"\"\"\n",
    "    for i, l in enumerate(model.layers):\n",
    "        print(i, 'cls={} name={}'.format(type(l).__name__, l.name))\n",
    "        weights = l.get_weights()\n",
    "        print_str = ''\n",
    "        for weight in weights:\n",
    "            print_str += str_shape(weight) + ' '\n",
    "        print(print_str)\n",
    "        print()\n",
    "\n",
    "\n",
    "class SimpleContext(Lambda):\n",
    "    \"\"\"Class to implement `simple_context` method as a Keras layer.\"\"\"\n",
    "\n",
    "    def __init__(self, fn, rnn_size, **kwargs):\n",
    "        \"\"\"Initialize SimpleContext.\"\"\"\n",
    "        self.rnn_size = rnn_size\n",
    "        super(SimpleContext, self).__init__(fn, **kwargs)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        \"\"\"Compute mask of maxlend.\"\"\"\n",
    "        return input_mask[:, maxlend:]\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        \"\"\"Get output shape for a given `input_shape`.\"\"\"\n",
    "        nb_samples = input_shape[0]\n",
    "        n = 2 * (self.rnn_size - activation_rnn_size)\n",
    "        return (nb_samples, maxlenh, n)\n",
    "\n",
    "\n",
    "def create_model(vocab_size, embedding_size, LR, rnn_layers, rnn_size, embedding=None):\n",
    "    \"\"\"Construct and compile LSTM model.\"\"\"\n",
    "    # create a standard stacked LSTM\n",
    "    if embedding is not None:\n",
    "        embedding = [embedding]\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_size,\n",
    "                        input_length=maxlen,\n",
    "                        W_regularizer=regularizer, dropout=p_emb, weights=embedding, mask_zero=True,\n",
    "                        name='embedding_1'))\n",
    "    for i in range(rnn_layers):\n",
    "        lstm = LSTM(rnn_size, return_sequences=True,\n",
    "                    W_regularizer=regularizer, U_regularizer=regularizer,\n",
    "                    b_regularizer=regularizer, dropout_W=p_W, dropout_U=p_U,\n",
    "                    name='lstm_{}'.format(i + 1))\n",
    "        model.add(lstm)\n",
    "        model.add(Dropout(p_dense, name='dropout_{}'.format(i + 1)))\n",
    "\n",
    "    def simple_context(X, mask, n=activation_rnn_size):\n",
    "        \"\"\"Reduce the input just to its headline part (second half).\n",
    "\n",
    "        For each word in this part it concatenate the output of the previous layer (RNN)\n",
    "        with a weighted average of the outputs of the description part.\n",
    "        In this only the last `rnn_size - activation_rnn_size` are used from each output.\n",
    "        The first `activation_rnn_size` output is used to computer the weights for the averaging.\n",
    "        \"\"\"\n",
    "        desc, head = X[:, :maxlend, :], X[:, maxlend:, :]\n",
    "        head_activations, head_words = head[:, :, :n], head[:, :, n:]\n",
    "        desc_activations, desc_words = desc[:, :, :n], desc[:, :, n:]\n",
    "\n",
    "        # RTFM http://deeplearning.net/software/theano/library/tensor/basic.html#theano.tensor.batched_tensordot\n",
    "        # activation for every head word and every desc word\n",
    "        activation_energies = K.batch_dot(head_activations, desc_activations, axes=(2, 2))\n",
    "        # make sure we dont use description words that are masked out\n",
    "        if mask is not None:\n",
    "            param = 1. - K.cast(mask[:, :maxlend], 'float32')\n",
    "            activation_energies = activation_energies + -1e20 * K.expand_dims(param, 1)\n",
    "\n",
    "        # for every head word compute weights for every desc word\n",
    "        activation_energies = K.reshape(activation_energies, (-1, maxlend))\n",
    "        activation_weights = K.softmax(activation_energies)\n",
    "        activation_weights = K.reshape(activation_weights, (-1, maxlenh, maxlend))\n",
    "\n",
    "        # for every head word compute weighted average of desc words\n",
    "        desc_avg_word = K.batch_dot(activation_weights, desc_words, axes=(2, 1))\n",
    "        return K.concatenate((desc_avg_word, head_words))\n",
    "\n",
    "    if activation_rnn_size:\n",
    "        model.add(SimpleContext(simple_context, rnn_size, name='simplecontext_1'))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(\n",
    "        vocab_size,\n",
    "        W_regularizer=regularizer,\n",
    "        b_regularizer=regularizer,\n",
    "        name='time_distributed_2')))\n",
    "    model.add(Activation('softmax', name='activation_1'))\n",
    "\n",
    "    # opt = Adam(lr=LR)  # keep calm and reduce learning rate\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    K.set_value(model.optimizer.lr, np.float32(LR))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Generate samples.\n",
    "\n",
    "Variation on https://github.com/ryankiros/skip-thoughts/blob/master/decoding/search.py\n",
    "\"\"\"\n",
    "\n",
    "def lpadd(x):\n",
    "    \"\"\"Left (pre) pad a description to maxlend and then add eos.\n",
    "\n",
    "    The eos is the input to predicting the first word in the headline\n",
    "    \"\"\"\n",
    "    assert maxlend >= 0\n",
    "    if maxlend == 0:\n",
    "        return [eos]\n",
    "    n = len(x)\n",
    "    if n > maxlend:\n",
    "        x = x[-maxlend:]\n",
    "        n = maxlend\n",
    "    return [empty] * (maxlend - n) + x + [eos]\n",
    "\n",
    "\n",
    "def beamsearch(\n",
    "        predict, start, k, maxsample, use_unk, empty, temperature, nb_unknown_words,\n",
    "        vocab_size, model, batch_size, avoid=None, avoid_score=1):\n",
    "    \"\"\"Return k samples (beams) and their NLL scores, each sample is a sequence of labels.\n",
    "\n",
    "    All samples starts with an `empty` label and end with `eos` or truncated to length of `maxsample`.\n",
    "    You need to supply `predict` which returns the label probability of each sample.\n",
    "    `use_unk` allow usage of `oov` (out-of-vocabulary) label in samples.\n",
    "    \"\"\"\n",
    "    def sample(energy, n, temperature=temperature):\n",
    "        \"\"\"Sample at most n elements according to their energy.\"\"\"\n",
    "        n = min(n, len(energy))\n",
    "        prb = np.exp(-np.array(energy) / temperature)\n",
    "        res = []\n",
    "        for i in range(n):\n",
    "            z = np.sum(prb)\n",
    "            r = np.argmax(np.random.multinomial(1, prb / z, 1))\n",
    "            res.append(r)\n",
    "            prb[r] = 0.  # make sure we select each element only once\n",
    "        return res\n",
    "\n",
    "    dead_samples = []\n",
    "    dead_scores = []\n",
    "    live_k = 1  # samples that did not yet reached eos\n",
    "    live_samples = [list(start)]\n",
    "    live_scores = [0]\n",
    "\n",
    "    while live_k:\n",
    "        # for every possible live sample calc prob for every possible label\n",
    "        probs = predict(live_samples, empty=empty, model=model, batch_size=batch_size)\n",
    "\n",
    "        # total score for every sample is sum of -log of word prb\n",
    "        cand_scores = np.array(live_scores)[:, None] - np.log(probs)\n",
    "        cand_scores[:, empty] = 1e20\n",
    "        if not use_unk:\n",
    "            for i in range(nb_unknown_words):\n",
    "                cand_scores[:, vocab_size - 1 - i] = 1e20\n",
    "\n",
    "        if avoid:\n",
    "            for a in avoid:\n",
    "                for i, s in enumerate(live_samples):\n",
    "                    n = len(s) - len(start)\n",
    "                    if n < len(a):\n",
    "                        # at this point live_sample is before the new word,\n",
    "                        # which should be avoided, is added\n",
    "                        cand_scores[i, a[n]] += avoid_score\n",
    "\n",
    "        live_scores = list(cand_scores.flatten())\n",
    "\n",
    "        # find the best (lowest) scores we have from all possible dead samples and\n",
    "        # all live samples and all possible new words added\n",
    "        scores = dead_scores + live_scores\n",
    "        ranks = sample(scores, k)\n",
    "        n = len(dead_scores)\n",
    "        ranks_dead = [r for r in ranks if r < n]\n",
    "        ranks_live = [r - n for r in ranks if r >= n]\n",
    "\n",
    "        dead_scores = [dead_scores[r] for r in ranks_dead]\n",
    "        dead_samples = [dead_samples[r] for r in ranks_dead]\n",
    "\n",
    "        live_scores = [live_scores[r] for r in ranks_live]\n",
    "\n",
    "        # append the new words to their appropriate live sample\n",
    "        voc_size = probs.shape[1]\n",
    "        live_samples = [live_samples[r // voc_size] + [r % voc_size] for r in ranks_live]\n",
    "\n",
    "        # live samples that should be dead are...\n",
    "        # even if len(live_samples) == maxsample we dont want it dead because we want one\n",
    "        # last prediction out of it to reach a headline of maxlenh\n",
    "        zombie = [s[-1] == eos or len(s) > maxsample for s in live_samples]\n",
    "\n",
    "        # add zombies to the dead\n",
    "        dead_samples += [s for s, z in zip(live_samples, zombie) if z]\n",
    "        dead_scores += [s for s, z in zip(live_scores, zombie) if z]\n",
    "        # remove zombies from the living\n",
    "        live_samples = [s for s, z in zip(live_samples, zombie) if not z]\n",
    "        live_scores = [s for s, z in zip(live_scores, zombie) if not z]\n",
    "        live_k = len(live_samples)\n",
    "\n",
    "    return dead_samples + live_samples, dead_scores + live_scores\n",
    "\n",
    "\n",
    "def keras_rnn_predict(samples, empty, model, batch_size):\n",
    "    \"\"\"For every sample, calculate probability for every possible label.\n",
    "\n",
    "    You need to supply your RNN model and maxlen - the length of sequences it can handle\n",
    "    \"\"\"\n",
    "    sample_lengths = list(map(len, samples))\n",
    "    assert all(l > maxlend for l in sample_lengths)\n",
    "    assert all(l[maxlend] == eos for l in samples)\n",
    "    # pad from right (post) so the first maxlend will be description followed by headline\n",
    "    data = sequence.pad_sequences(samples, maxlen=maxlen, value=empty, padding='post', truncating='post')\n",
    "    probs = model.predict(data, verbose=0, batch_size=batch_size)\n",
    "    return np.array([prob[sample_length - maxlend - 1]\n",
    "                     for prob, sample_length in zip(probs, sample_lengths)])\n",
    "\n",
    "\n",
    "def vocab_fold(xs, oov0, glove_idx2idx, vocab_size, nb_unknown_words):\n",
    "    \"\"\"Convert list of word indices that may contain words outside vocab_size to words inside.\n",
    "\n",
    "    If a word is outside, try first to use glove_idx2idx to find a similar word inside.\n",
    "    If none exist then replace all accurancies of the same unknown word with <0>, <1>, ...\n",
    "    \"\"\"\n",
    "    xs = [x if x < oov0 else glove_idx2idx.get(x, x) for x in xs]\n",
    "    # the more popular word is <0> and so on\n",
    "    outside = sorted([x for x in xs if x >= oov0])\n",
    "    # if there are more than nb_unknown_words oov words then put them all in nb_unknown_words-1\n",
    "    outside = dict((x, vocab_size - 1 - min(i, nb_unknown_words - 1)) for i, x in enumerate(outside))\n",
    "    xs = [outside.get(x, x) for x in xs]\n",
    "    return xs\n",
    "\n",
    "\n",
    "def vocab_unfold(desc, xs, oov0):\n",
    "    \"\"\"Covert a description to a list of word indices.\"\"\"\n",
    "    # assume desc is the unfolded version of the start of xs\n",
    "    unfold = {}\n",
    "    for i, unfold_idx in enumerate(desc):\n",
    "        fold_idx = xs[i]\n",
    "        if fold_idx >= oov0:\n",
    "            unfold[fold_idx] = unfold_idx\n",
    "    return [unfold.get(x, x) for x in xs]\n",
    "\n",
    "\n",
    "def gensamples(\n",
    "        skips, short, data, idx2word, oov0, glove_idx2idx, vocab_size,\n",
    "        nb_unknown_words, avoid=None, avoid_score=1, **kwargs):\n",
    "    \"\"\"Generate text samples.\"\"\"\n",
    "    # unpack data\n",
    "    X, Y = data\n",
    "\n",
    "    # if data is full dataset pick a random header and description\n",
    "    if not isinstance(X[0], int):\n",
    "        i = random.randint(0, len(X) - 1)\n",
    "        x = X[i]\n",
    "        y = Y[i]\n",
    "    else:\n",
    "        x = X\n",
    "        y = Y\n",
    "\n",
    "    # print header and description\n",
    "    print('HEAD:', ' '.join(idx2word[w] for w in y[:maxlenh]))\n",
    "    print('DESC:', ' '.join(idx2word[w] for w in x[:maxlend]))\n",
    "\n",
    "    if avoid:\n",
    "        # avoid is a list of avoids. Each avoid is a string or list of word indeicies\n",
    "        if isinstance(avoid, str) or isinstance(avoid[0], int):\n",
    "            avoid[avoid]\n",
    "        avoid = [a.split() if isinstance(a, str) else a for a in avoid]\n",
    "        avoid = [[a] for a in avoid]\n",
    "\n",
    "    print('HEADS:')\n",
    "    samples = []\n",
    "    if maxlend == 0:\n",
    "        skips = [0]\n",
    "    else:\n",
    "        skips = range(min(maxlend, len(x)), max(maxlend, len(x)), abs(maxlend - len(x)) // skips + 1)\n",
    "    for s in skips:\n",
    "        start = lpadd(x[:s])\n",
    "        fold_start = vocab_fold(start, oov0, glove_idx2idx, vocab_size, nb_unknown_words)\n",
    "        sample, score = beamsearch(\n",
    "            predict=keras_rnn_predict,\n",
    "            start=fold_start,\n",
    "            maxsample=maxlen,\n",
    "            empty=empty,\n",
    "            nb_unknown_words=nb_unknown_words,\n",
    "            vocab_size=vocab_size,\n",
    "            avoid=avoid,\n",
    "            **kwargs\n",
    "        )\n",
    "        assert all(s[maxlend] == eos for s in sample)\n",
    "        samples += [(s, start, scr) for s, scr in zip(sample, score)]\n",
    "\n",
    "    samples.sort(key=lambda x: x[-1])\n",
    "    codes = []\n",
    "    for sample, start, score in samples:\n",
    "        code = ''\n",
    "        words = []\n",
    "        sample = vocab_unfold(start, sample, oov0)[len(start):]\n",
    "        for w in sample:\n",
    "            if w == eos:\n",
    "                break\n",
    "            words.append(idx2word[w])\n",
    "            code += chr(w // (256 * 256)) + chr((w // 256) % 256) + chr(w % 256)\n",
    "\n",
    "        if short:\n",
    "            distance = min([100] + [-Levenshtein.jaro(code, c) for c in codes])\n",
    "            if distance > -0.6:\n",
    "                print(score, ' '.join(words))\n",
    "        else:\n",
    "                print(score, ' '.join(words))\n",
    "        codes.append(code)\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Data generator generates batches of inputs and outputs/labels for training.\n",
    "\n",
    "The inputs are each made from two parts. The first maxlend words are the original description, followed by `eos` followed by the headline which we want to predict, except for the last word in the headline which is always `eos` and then `empty` padding until `maxlen` words.\n",
    "\n",
    "For each, input, the output is the headline words (without the start `eos` but with the ending `eos`) padded with `empty` words up to `maxlenh` words. The output is also expanded to be y-hot encoding of each word.\n",
    "\n",
    "To be more realistic, the second part of the input should be the result of generation and not the original headline.\n",
    "Instead we will flip just `nflips` words to be from the generator, but even this is too hard and instead\n",
    "implement flipping in a naive way (which consumes less time.) Using the full input (description + eos + headline) generate predictions for outputs. Faor nflips random words from the output, replace the original word with the word with highest probability from the prediction.\n",
    "\"\"\"\n",
    "\n",
    "def flip_headline(x, nflips, model, debug, oov0, idx2word):\n",
    "    \"\"\"Flip some of the words in the second half (headline) with words predicted by the model.\"\"\"\n",
    "    if nflips is None or model is None or nflips <= 0:\n",
    "        return x\n",
    "\n",
    "    batch_size = len(x)\n",
    "    assert np.all(x[:, maxlend] == eos)\n",
    "    probs = model.predict(x, verbose=0, batch_size=batch_size)\n",
    "    x_out = x.copy()\n",
    "    for b in range(batch_size):\n",
    "        # pick locations we want to flip\n",
    "        # 0...maxlend-1 are descriptions and should be fixed\n",
    "        # maxlend is eos and should be fixed\n",
    "        flips = sorted(random.sample(range(maxlend + 1, maxlen), nflips))\n",
    "        if debug and b < debug:\n",
    "            print(b)\n",
    "        for input_idx in flips:\n",
    "            if x[b, input_idx] == empty or x[b, input_idx] == eos:\n",
    "                continue\n",
    "            # convert from input location to label location\n",
    "            # the output at maxlend (when input is eos) is feed as input at maxlend+1\n",
    "            label_idx = input_idx - (maxlend + 1)\n",
    "            prob = probs[b, label_idx]\n",
    "            w = prob.argmax()\n",
    "            if w == empty:  # replace accidental empty with oov\n",
    "                w = oov0\n",
    "            if debug and b < debug:\n",
    "                print('{} => {}'.format(idx2word[x_out[b, input_idx]], idx2word[w]),)\n",
    "            x_out[b, input_idx] = w\n",
    "        if debug and b < debug:\n",
    "            print()\n",
    "    return x_out\n",
    "\n",
    "\n",
    "def conv_seq_labels(xds, xhs, nflips, model, debug, oov0, glove_idx2idx, vocab_size, nb_unknown_words, idx2word):\n",
    "    \"\"\"Convert description and hedlines to padded input vectors; headlines are one-hot to label.\"\"\"\n",
    "    batch_size = len(xhs)\n",
    "    assert len(xds) == batch_size\n",
    "    x = [\n",
    "        vocab_fold(lpadd(xd) + xh, oov0, glove_idx2idx, vocab_size, nb_unknown_words)\n",
    "        for xd, xh in zip(xds, xhs)]  # the input does not have 2nd eos\n",
    "    x = sequence.pad_sequences(x, maxlen=maxlen, value=empty, padding='post', truncating='post')\n",
    "    x = flip_headline(x, nflips=nflips, model=model, debug=debug, oov0=oov0, idx2word=idx2word)\n",
    "\n",
    "    y = np.zeros((batch_size, maxlenh, vocab_size))\n",
    "    for i, xh in enumerate(xhs):\n",
    "        xh = vocab_fold(xh, oov0, glove_idx2idx, vocab_size, nb_unknown_words) + [eos] + [empty] * maxlenh  # output does have a eos at end\n",
    "        xh = xh[:maxlenh]\n",
    "        y[i, :, :] = np_utils.to_categorical(xh, vocab_size)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def gen(Xd, Xh, batch_size, nb_batches, nflips, model, debug, oov0, glove_idx2idx, vocab_size, nb_unknown_words, idx2word):\n",
    "    \"\"\"Yield batches.\n",
    "\n",
    "    for training use nb_batches=None\n",
    "    for validation generate deterministic results repeating every nb_batches\n",
    "    \"\"\"\n",
    "    # while training it is good idea to flip once in a while the values of the headlines from the\n",
    "    # value taken from Xh to value generated by the model.\n",
    "    c = nb_batches if nb_batches else 0\n",
    "    while True:\n",
    "        xds = []\n",
    "        xhs = []\n",
    "        if nb_batches and c >= nb_batches:\n",
    "            c = 0\n",
    "        new_seed = random.randint(0, 2e10)\n",
    "        random.seed(c + 123456789 + seed)\n",
    "        for b in range(batch_size):\n",
    "            t = random.randint(0, len(Xd) - 1)\n",
    "\n",
    "            xd = Xd[t]\n",
    "            s = random.randint(min(maxlend, len(xd)), max(maxlend, len(xd)))\n",
    "            xds.append(xd[:s])\n",
    "\n",
    "            xh = Xh[t]\n",
    "            s = random.randint(min(maxlenh, len(xh)), max(maxlenh, len(xh)))\n",
    "            xhs.append(xh[:s])\n",
    "\n",
    "        # undo the seeding before we yield inorder not to affect the caller\n",
    "        c += 1\n",
    "        random.seed(new_seed)\n",
    "\n",
    "        yield conv_seq_labels(\n",
    "            xds,\n",
    "            xhs,\n",
    "            nflips=nflips,\n",
    "            model=model,\n",
    "            debug=debug,\n",
    "            oov0=oov0,\n",
    "            glove_idx2idx=glove_idx2idx,\n",
    "            vocab_size=vocab_size,\n",
    "            nb_unknown_words=nb_unknown_words,\n",
    "            idx2word=idx2word,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of embedding space for words: 100\n",
      "vocabulary size: 40,000 the last 10 words can be used as place holders for unknown/oov words\n",
      "total number of different words: 90,818\n",
      "number of words outside vocabulary which we can substitue using glove similarity: 32,532\n",
      "number of words that will be regarded as unknonw(unk)/out-of-vocabulary(oov): 18,286\n",
      "number of examples 500000 500000\n",
      "Random head, description:\n",
      "H: un chief condemns somalia suicide blast\n",
      "\n",
      "D: un chief ban ki-moon thursday denounced a suicide attack on a somali graduation ceremony which left ## people dead including three government ministers .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(40000, 100, input_length=35, weights=[array([[-..., mask_zero=True, name=\"embedding_1\", embeddings_regularizer=None)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, return_sequences=True, name=\"lstm_1\", kernel_regularizer=None, bias_regularizer=None, recurrent_regularizer=None, dropout=0, recurrent_dropout=0)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, return_sequences=True, name=\"lstm_2\", kernel_regularizer=None, bias_regularizer=None, recurrent_regularizer=None, dropout=0, recurrent_dropout=0)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, return_sequences=True, name=\"lstm_3\", kernel_regularizer=None, bias_regularizer=None, recurrent_regularizer=None, dropout=0, recurrent_dropout=0)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(40000, name=\"timedistributed_1\", kernel_regularizer=None, bias_regularizer=None)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cls=Embedding name=embedding_1\n",
      "40000x100 \n",
      "\n",
      "1 cls=LSTM name=lstm_1\n",
      "100x2048 512x2048 2048 \n",
      "\n",
      "2 cls=Dropout name=dropout_1\n",
      "\n",
      "\n",
      "3 cls=LSTM name=lstm_2\n",
      "512x2048 512x2048 2048 \n",
      "\n",
      "4 cls=Dropout name=dropout_2\n",
      "\n",
      "\n",
      "5 cls=LSTM name=lstm_3\n",
      "512x2048 512x2048 2048 \n",
      "\n",
      "6 cls=Dropout name=dropout_3\n",
      "\n",
      "\n",
      "7 cls=SimpleContext name=simplecontext_1\n",
      "\n",
      "\n",
      "8 cls=TimeDistributed name=time_distributed_2\n",
      "944x40000 40000 \n",
      "\n",
      "9 cls=Activation name=activation_1\n",
      "\n",
      "\n",
      "HEAD: obama clinton pledge us support for aids fight\n",
      "DESC: president barack obama and secretary of state hillary rodham clinton have pledged the support of the united states in the global fight against aids .\n",
      "HEADS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1029s 2s/step - loss: 7.7715 - val_loss: 7.5011\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1026s 2s/step - loss: 7.3500 - val_loss: 7.1762\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1025s 2s/step - loss: 7.0481 - val_loss: 6.9895\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1028s 2s/step - loss: 6.8892 - val_loss: 6.8327\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1028s 2s/step - loss: 6.7359 - val_loss: 6.6672\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1030s 2s/step - loss: 6.5877 - val_loss: 6.5413\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 1031s 2s/step - loss: 6.4747 - val_loss: 6.4282\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 1032s 2s/step - loss: 6.3919 - val_loss: 6.3386\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 1033s 2s/step - loss: 6.3057 - val_loss: 6.2819\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 1036s 2s/step - loss: 6.2325 - val_loss: 6.2114\n",
      "HEAD: policewomen^ hit the streets in iran\n",
      "DESC: more than ### women graduated from iran 's female police academy saturday , the second only such graduation since the #### islamic revolution .\n",
      "HEADS:\n",
      "17.261718273162842 police police in in\n",
      "18.751840829849243 police police in in in\n",
      "19.802207231521606 police police in in for\n",
      "21.732557892799377 police police in in of in\n",
      "23.291698455810547 police police in in of to\n",
      "23.350178003311157 police police in in in with\n",
      "28.279115200042725 police police in in in with 's\n",
      "35.95909833908081 police police in in of in bangladesh since\n",
      "36.81393754482269 police police in in of in bangladesh find\n",
      "37.4594241976738 police police in in in with 's marriages\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Train a sequence to sequence model.\n",
    "\n",
    "This script is sourced from Siraj Rival\n",
    "https://github.com/llSourcell/How_to_make_a_text_summarizer/blob/master/train.ipynb\n",
    "\"\"\"\n",
    "\n",
    "epochs=10\n",
    "rnn_size=512\n",
    "rnn_layers=3\n",
    "nsamples=640\n",
    "nflips=0\n",
    "temperature=.8\n",
    "lr=0.0001\n",
    "warm_start='store_true'\n",
    "batch_size=32\n",
    "\n",
    "# set sample sizes\n",
    "nb_train_samples = np.int(np.floor(nsamples / batch_size)) * batch_size  # num training samples\n",
    "nb_val_samples = nb_train_samples  # num validation samples\n",
    "\n",
    "# seed weight initialization\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "embedding, idx2word, word2idx, glove_idx2idx = load_embedding(nb_unknown_words)\n",
    "vocab_size, embedding_size = embedding.shape\n",
    "oov0 = vocab_size - nb_unknown_words\n",
    "idx2word = process_vocab(idx2word, vocab_size, oov0, nb_unknown_words)\n",
    "X_train, X_test, Y_train, Y_test = load_split_data(nb_val_samples, seed)\n",
    "\n",
    "# print a sample recipe to make sure everything looks right\n",
    "print('Random head, description:')\n",
    "i = 811\n",
    "prt('H', Y_train[i], idx2word)\n",
    "prt('D', X_train[i], idx2word)\n",
    "\n",
    "# save model initialization parameters\n",
    "model_params = (dict(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=embedding_size,\n",
    "    LR=lr,\n",
    "    rnn_layers=rnn_layers,\n",
    "    rnn_size=rnn_size,\n",
    "))\n",
    "with open('model_params.json', 'w') as f:\n",
    "    json.dump(model_params, f)\n",
    "\n",
    "\n",
    "model = create_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=embedding_size,\n",
    "    LR=lr,\n",
    "    embedding=embedding,\n",
    "    rnn_layers=rnn_layers,\n",
    "    rnn_size=rnn_size,\n",
    ")\n",
    "inspect_model(model)\n",
    "\n",
    "# load pre-trained model weights\n",
    "FN1_filename = '{}.hdf5'.format(FN1)\n",
    "if warm_start and FN1 and os.path.exists(FN1_filename):\n",
    "    model.load_weights(FN1_filename)\n",
    "    print('Model weights loaded from {}'.format(FN1_filename))\n",
    "\n",
    "# print samples before training\n",
    "gensamples(\n",
    "    skips=2,\n",
    "    k=10,\n",
    "    batch_size=batch_size,\n",
    "    short=False,\n",
    "    temperature=temperature,\n",
    "    use_unk=True,\n",
    "    model=model,\n",
    "    data=(X_test, Y_test),\n",
    "    idx2word=idx2word,\n",
    "    oov0=oov0,\n",
    "    glove_idx2idx=glove_idx2idx,\n",
    "    vocab_size=vocab_size,\n",
    "    nb_unknown_words=nb_unknown_words,\n",
    ")\n",
    "\n",
    "# get train and validation generators\n",
    "r = next(gen(X_train, Y_train, batch_size=batch_size, nb_batches=None, nflips=None, model=None, debug=False, oov0=oov0, glove_idx2idx=glove_idx2idx, vocab_size=vocab_size, nb_unknown_words=nb_unknown_words, idx2word=idx2word))\n",
    "traingen = gen(X_train, Y_train, batch_size=batch_size, nb_batches=None, nflips=nflips, model=model, debug=False, oov0=oov0, glove_idx2idx=glove_idx2idx, vocab_size=vocab_size, nb_unknown_words=nb_unknown_words, idx2word=idx2word)\n",
    "valgen = gen(X_test, Y_test, batch_size=batch_size, nb_batches=nb_val_samples // batch_size, nflips=None, model=None, debug=False, oov0=oov0, glove_idx2idx=glove_idx2idx, vocab_size=vocab_size, nb_unknown_words=nb_unknown_words, idx2word=idx2word)\n",
    "\n",
    "# define callbacks for training\n",
    "callbacks = [TensorBoard(\n",
    "    log_dir=str(time.time()),\n",
    "    histogram_freq=0, write_graph=False, write_images=False)]\n",
    "\n",
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights(FN1_filename, overwrite=True)\n",
    "\n",
    "# print samples after training\n",
    "samples = gensamples(\n",
    "    skips=2,\n",
    "    k=10,\n",
    "    batch_size=batch_size,\n",
    "    short=False,\n",
    "    temperature=temperature,\n",
    "    use_unk=True,\n",
    "    model=model,\n",
    "    data=(X_test, Y_test),\n",
    "    idx2word=idx2word,\n",
    "    oov0=oov0,\n",
    "    glove_idx2idx=glove_idx2idx,\n",
    "    vocab_size=vocab_size,\n",
    "    nb_unknown_words=nb_unknown_words,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: an indonesian court on thursday found a man guilty of complicity in a dormitory explosion here last year which killed three acehnese students .\n",
      "HEADS:\n",
      "49.32130187749863 prosecutor police ecuadorean attacks australians man death in\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Predict a title for a recipe.\"\"\"\n",
    "\n",
    "# set seeds in random libraries\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "def load_weights(model, filepath):\n",
    "    \"\"\"Load all weights possible into model from filepath.\n",
    "\n",
    "    This is a modified version of keras load_weights that loads as much as it can\n",
    "    if there is a mismatch between file and model. It returns the weights\n",
    "    of the first layer in which the mismatch has happened\n",
    "    \"\"\"\n",
    "    print('Loading', filepath, 'to', model.name)\n",
    "    with h5py.File(filepath, mode='r') as f:\n",
    "        # new file format\n",
    "        layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n",
    "\n",
    "        # we batch weight value assignments in a single backend call\n",
    "        # which provides a speedup in TensorFlow.\n",
    "        weight_value_tuples = []\n",
    "        for name in layer_names:\n",
    "            print(name)\n",
    "            g = f[name]\n",
    "            weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n",
    "            if len(weight_names):\n",
    "                weight_values = [g[weight_name] for weight_name in weight_names]\n",
    "                try:\n",
    "                    layer = model.get_layer(name=name)\n",
    "                except:\n",
    "                    layer = None\n",
    "                if not layer:\n",
    "                    print('failed to find layer', name, 'in model')\n",
    "                    print('weights', ' '.join(str_shape(w) for w in weight_values))\n",
    "                    print('stopping to load all other layers')\n",
    "                    weight_values = [np.array(w) for w in weight_values]\n",
    "                    break\n",
    "                symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n",
    "                weight_value_tuples += zip(symbolic_weights, weight_values)\n",
    "                weight_values = None\n",
    "        K.batch_set_value(weight_value_tuples)\n",
    "    return weight_values\n",
    "\n",
    "\n",
    "def main(sample_str=None):\n",
    "    '''\n",
    "    \"\"\"Predict a title for a recipe.\"\"\"\n",
    "    # load model parameters used for training\n",
    "    with open('model_params.json', 'r') as f:\n",
    "        model_params = json.load(f)\n",
    "\n",
    "    # create placeholder model\n",
    "    model = create_model(**model_params)\n",
    "\n",
    "    # load weights from training run\n",
    "    load_weights(model, '{}.hdf5'.format(FN1))\n",
    "    '''\n",
    "    # load recipe titles and descriptions\n",
    "    with open('vocabulary-embedding.data.pkl', 'rb') as fp:\n",
    "        X_data, Y_data = pickle.load(fp)\n",
    "\n",
    "    # load vocabulary\n",
    "    with open('{}.pkl'.format(FN0), 'rb') as fp:\n",
    "        embedding, idx2word, word2idx, glove_idx2idx = pickle.load(fp)\n",
    "    vocab_size, embedding_size = embedding.shape\n",
    "    oov0 = vocab_size - nb_unknown_words\n",
    "\n",
    "    if sample_str is None:\n",
    "        # load random recipe description if none provided\n",
    "        i = np.random.randint(len(X_data))\n",
    "        sample_str = ''\n",
    "        sample_title = ''\n",
    "        for w in X_data[i]:\n",
    "            sample_str += idx2word[w] + ' '\n",
    "        for w in Y_data[i]:\n",
    "            sample_title += idx2word[w] + ' '\n",
    "        y = Y_data[i]\n",
    "        print('Randomly sampled recipe:')\n",
    "        print(sample_title)\n",
    "        print(sample_str)\n",
    "    else:\n",
    "        sample_title = ''\n",
    "        y = [eos]\n",
    "\n",
    "    x = [word2idx[w.rstrip('^')] for w in sample_str.split()]\n",
    "\n",
    "    samples = gensamples(\n",
    "        skips=2,\n",
    "        k=1,\n",
    "        batch_size=2,\n",
    "        short=False,\n",
    "        temperature=1.,\n",
    "        use_unk=True,\n",
    "        model=model,\n",
    "        data=(x, y),\n",
    "        idx2word=idx2word,\n",
    "        oov0=oov0,\n",
    "        glove_idx2idx=glove_idx2idx,\n",
    "        vocab_size=vocab_size,\n",
    "        nb_unknown_words=nb_unknown_words,\n",
    "    )\n",
    "\n",
    "    headline = samples[0][0][len(samples[0][1]):]\n",
    "    ' '.join(idx2word[w] for w in headline)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sample_str=X_data[5002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some ### demonstrators rallied in central prague on thursday and burned an israeli flag to protest against the military offensive in the palestinian territories .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[5001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: australian shares closed down #.# percent monday following a weak lead from the united states and lower commodity prices , dealers said .\n",
      "HEADS:\n",
      "17.893243551254272 european prices close #.# percent down\n"
     ]
    }
   ],
   "source": [
    "main(X_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "coyotes select top-rated goalie \n",
      "the loudest applause during saturday 's entire nhl entry draft came when the coyotes , of all teams , made their first-round selection . \n",
      "HEAD: coyotes select top-rated goalie\n",
      "DESC: the loudest applause during saturday 's entire nhl entry draft came when the coyotes , of all teams , made their first-round selection .\n",
      "HEADS:\n",
      "69.51377285271883 travis control with plans third deal away has tie\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "cartoons give social satire and multiculturalism a whirl \n",
      "television 's world of animation is tumbling out far beyond the confines of saturday-morning cartoons for selling toys . \n",
      "HEAD: cartoons give social satire and multiculturalism a whirl\n",
      "DESC: television 's world of animation is tumbling out far beyond the confines of saturday-morning cartoons for selling toys .\n",
      "HEADS:\n",
      "48.186828911304474 nissan with chicken for as concerned in\n",
      "62.302042067050934 <unk> marines baxter pay festivals drought use\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "venezuela issues bonds for us$ # billion \n",
      "venezuela will issue bonds for us$ # billion -lrb- euro### million -rrb- on the local market , a government official said monday . \n",
      "HEAD: venezuela issues bonds for us$ # billion\n",
      "DESC: venezuela will issue bonds for us$ # billion -lrb- euro### million -rrb- on the local market , a government official said monday .\n",
      "HEADS:\n",
      "58.19530925154686 restrictions french surge broadcasting to in #.# outsider\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "aussies keep firm grip on ashes \n",
      "world champions australia retained the ashes here on sunday with a ##-# victory over great britain in the third and final test . \n",
      "HEAD: aussies keep firm grip on ashes\n",
      "DESC: world champions australia retained the ashes here on sunday with a ##-# victory over great britain in the third and final test .\n",
      "HEADS:\n",
      "40.859228014945984 u.s. with haiti team for 's\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "arsenal manager accuses critics of racist thinking \n",
      "arsenal manager arsene wenger on friday defended the lack of english players on his gunners squad and accused his critics of racist thinking . \n",
      "HEAD: arsenal manager accuses critics of racist thinking\n",
      "DESC: arsenal manager arsene wenger on friday defended the lack of english players on his gunners squad and accused his critics of racist thinking .\n",
      "HEADS:\n",
      "37.46626925468445 schalk says their at to out\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1037s 2s/step - loss: 6.1753 - val_loss: 6.1589\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1037s 2s/step - loss: 6.1332 - val_loss: 6.1029\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1043s 2s/step - loss: 6.0746 - val_loss: 6.0598\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1041s 2s/step - loss: 6.0262 - val_loss: 6.0143\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1049s 2s/step - loss: 5.9716 - val_loss: 5.9640\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1045s 2s/step - loss: 5.9246 - val_loss: 5.9356\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 1042s 2s/step - loss: 5.8926 - val_loss: 5.9018\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 1043s 2s/step - loss: 5.8604 - val_loss: 5.8788\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 1041s 2s/step - loss: 5.8247 - val_loss: 5.8510\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 1041s 2s/step - loss: 5.7850 - val_loss: 5.8220\n"
     ]
    }
   ],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights(FN1_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: an indonesian court on thursday found a man guilty of complicity in a dormitory explosion here last year which killed three acehnese students .\n",
      "HEADS:\n",
      "50.53463840484619 mourning sentences killed ## out accident skull\n"
     ]
    }
   ],
   "source": [
    "main(X_data[5002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "cities sticking visitors with sports stadium costs \n",
      "one way to save money when you travel is to avoid any city with a serious professional sports franchise . \n",
      "HEAD: cities sticking visitors with sports stadium costs\n",
      "DESC: one way to save money when you travel is to avoid any city with a serious professional sports franchise .\n",
      "HEADS:\n",
      "35.682562828063965 more frigid prices rivalry\n",
      "76.46098418399924 trail nurses but huge a homeland trump of film\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1140s 2s/step - loss: 5.6642 - val_loss: 5.8062\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1140s 2s/step - loss: 5.6829 - val_loss: 5.7766\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1131s 2s/step - loss: 5.6340 - val_loss: 5.7428\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1119s 2s/step - loss: 5.6087 - val_loss: 5.7224\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1122s 2s/step - loss: 5.5869 - val_loss: 5.6892\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1128s 2s/step - loss: 5.5568 - val_loss: 5.6771\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 1121s 2s/step - loss: 5.5303 - val_loss: 5.6525\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 1121s 2s/step - loss: 5.5137 - val_loss: 5.6334\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 1126s 2s/step - loss: 5.4644 - val_loss: 5.6266\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 1128s 2s/step - loss: 5.4420 - val_loss: 5.5974\n"
     ]
    }
   ],
   "source": [
    "traingen = gen(X_train, Y_train, batch_size=batch_size, nb_batches=None, nflips=5, model=model, debug=False, oov0=oov0, glove_idx2idx=glove_idx2idx, vocab_size=vocab_size, nb_unknown_words=nb_unknown_words, idx2word=idx2word)\n",
    "valgen = gen(X_test, Y_test, batch_size=batch_size, nb_batches=nb_val_samples // batch_size, nflips=None, model=None, debug=False, oov0=oov0, glove_idx2idx=glove_idx2idx, vocab_size=vocab_size, nb_unknown_words=nb_unknown_words, idx2word=idx2word)\n",
    "\n",
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights(FN1_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: an indonesian court on thursday found a man guilty of complicity in a dormitory explosion here last year which killed three acehnese students .\n",
      "HEADS:\n",
      "34.98368340730667 woman convicted returns in claims child in\n"
     ]
    }
   ],
   "source": [
    "main(X_data[5002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'australian stocks close down #.# percent'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: australian shares closed down #.# percent monday following a weak lead from the united states and lower commodity prices , dealers said .\n",
      "HEADS:\n",
      "17.665944039821625 australian shares up up #.# of in\n"
     ]
    }
   ],
   "source": [
    "main(sample_str=X_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "katrina changes future for entire family \n",
      "last week , jamie and kenny <unk> gathered their four children around the kitchen table to discuss their future . \n",
      "HEAD: katrina changes future for entire family\n",
      "DESC: last week , jamie and kenny <unk> gathered their four children around the kitchen table to discuss their future .\n",
      "HEADS:\n",
      "51.71024560928345 sweet draw back gelatin help and at\n",
      "75.09842837551696 band flag die were cases defaced city the disease\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1124s 2s/step - loss: 5.4146 - val_loss: 5.5801\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1120s 2s/step - loss: 5.4007 - val_loss: 5.5484\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1112s 2s/step - loss: 5.3649 - val_loss: 5.5254\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1111s 2s/step - loss: 5.3384 - val_loss: 5.5066\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1119s 2s/step - loss: 5.2994 - val_loss: 5.4803\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1117s 2s/step - loss: 5.2729 - val_loss: 5.4642\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 1117s 2s/step - loss: 5.2575 - val_loss: 5.4531\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 1116s 2s/step - loss: 5.2429 - val_loss: 5.4500\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 1112s 2s/step - loss: 5.2223 - val_loss: 5.4322\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 1109s 2s/step - loss: 5.1901 - val_loss: 5.4286\n"
     ]
    }
   ],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights(FN1_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: an indonesian court on thursday found a man guilty of complicity in a dormitory explosion here last year which killed three acehnese students .\n",
      "HEADS:\n",
      "46.94695073366165 indonesian produces life death in boston shot kill\n"
     ]
    }
   ],
   "source": [
    "main(X_data[5002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: australian shares closed down #.# percent monday following a weak lead from the united states and lower commodity prices , dealers said .\n",
      "HEADS:\n",
      "7.943446628749371 australian shares close #.# #.# percent percent\n"
     ]
    }
   ],
   "source": [
    "main(sample_str=X_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "quake survivors bury their dead ramos tours devastated island \n",
      "president fidel ramos toured quake stricken mindoro rescue thursday as the death toll climbed to ## and mass burials began . \n",
      "HEAD: quake survivors bury their dead ramos tours devastated island\n",
      "DESC: president fidel ramos toured quake stricken mindoro rescue thursday as the death toll climbed to ## and mass burials began .\n",
      "HEADS:\n",
      "51.887038588523865 ahmadinejad confidence makes population positive deaths victims in\n",
      "72.65343773114728 haiti jack emergency blames arrived eruption closes road space\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 1117s 2s/step - loss: 5.2685 - val_loss: 5.3897\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1114s 2s/step - loss: 5.2456 - val_loss: 5.3753\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1115s 2s/step - loss: 5.2135 - val_loss: 5.3626\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1117s 2s/step - loss: 5.2129 - val_loss: 5.3505\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1124s 2s/step - loss: 5.1890 - val_loss: 5.3369\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1119s 2s/step - loss: 5.1612 - val_loss: 5.3083\n",
      "Epoch 7/10\n",
      "478/640 [=====================>........] - ETA: 3:49 - loss: 5.1777"
     ]
    }
   ],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights(FN1_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: an indonesian court on thursday found a man guilty of complicity in a dormitory explosion here last year which killed three acehnese students .\n",
      "HEADS:\n",
      "31.03696426771421 indonesian stock court convicted in mosques in #### bombings\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Predict a title for a recipe.\"\"\"\n",
    "\n",
    "# set seeds in random libraries\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "def load_weights(model, filepath):\n",
    "    \"\"\"Load all weights possible into model from filepath.\n",
    "\n",
    "    This is a modified version of keras load_weights that loads as much as it can\n",
    "    if there is a mismatch between file and model. It returns the weights\n",
    "    of the first layer in which the mismatch has happened\n",
    "    \"\"\"\n",
    "    print('Loading', filepath, 'to', model.name)\n",
    "    with h5py.File(filepath, mode='r') as f:\n",
    "        # new file format\n",
    "        layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n",
    "        print(layer_names)\n",
    "    \n",
    "        # we batch weight value assignments in a single backend call\n",
    "        # which provides a speedup in TensorFlow.\n",
    "        weight_value_tuples = []\n",
    "        for name in layer_names:\n",
    "            print(name)\n",
    "            g = f[name]\n",
    "            weight_names = [n.decode('utf8') for n in g.attrs['weight_names']]\n",
    "            if len(weight_names):\n",
    "                weight_values = [g[weight_name] for weight_name in weight_names]\n",
    "                try:\n",
    "                    layer = model.get_layer(name=name)\n",
    "                except:\n",
    "                    layer = None\n",
    "                if not layer:\n",
    "                    print('failed to find layer', name, 'in model')\n",
    "                    print('weights', ' '.join(str_shape(w) for w in weight_values))\n",
    "                    print('stopping to load all other layers')\n",
    "                    weight_values = [np.array(w) for w in weight_values]\n",
    "                    break\n",
    "                symbolic_weights = layer.trainable_weights + layer.non_trainable_weights\n",
    "                weight_value_tuples += zip(symbolic_weights, weight_values)\n",
    "                weight_values = None\n",
    "        K.batch_set_value(weight_value_tuples)\n",
    "    return weight_values\n",
    "    \n",
    "\n",
    "def main(sample_str=None):\n",
    "    '''\n",
    "    \"\"\"Predict a title for a recipe.\"\"\"\n",
    "    # load model parameters used for training\n",
    "    with open('model_params.json', 'r') as f:\n",
    "        model_params = json.load(f)\n",
    "    print(model_params)\n",
    "    # create placeholder model\n",
    "    model = create_model(**model_params)\n",
    "\n",
    "    # load weights from training run\n",
    "    load_weights(model, '{}.hdf5'.format(FN1))\n",
    "    '''\n",
    "    # load recipe titles and descriptions\n",
    "    with open('vocabulary-embedding.data.pkl', 'rb') as fp:\n",
    "        X_data, Y_data = pickle.load(fp)\n",
    "\n",
    "    # load vocabulary\n",
    "    with open('{}.pkl'.format(FN0), 'rb') as fp:\n",
    "        embedding, idx2word, word2idx, glove_idx2idx = pickle.load(fp)\n",
    "    vocab_size, embedding_size = embedding.shape\n",
    "    oov0 = vocab_size - nb_unknown_words\n",
    "\n",
    "    if sample_str is None:\n",
    "        # load random recipe description if none provided\n",
    "        i = np.random.randint(len(X_data))\n",
    "        sample_str = ''\n",
    "        sample_title = ''\n",
    "        for w in X_data[i]:\n",
    "            sample_str += idx2word[w] + ' '\n",
    "        for w in Y_data[i]:\n",
    "            sample_title += idx2word[w] + ' '\n",
    "        y = Y_data[i]\n",
    "        print('Randomly sampled recipe:')\n",
    "        print(sample_title)\n",
    "        print(sample_str)\n",
    "    else:\n",
    "        sample_title = ''\n",
    "        y = [eos]\n",
    "\n",
    "    x = [word2idx[w.rstrip('^')] for w in sample_str.split()]\n",
    "\n",
    "    samples = gensamples(\n",
    "        skips=2,\n",
    "        k=1,\n",
    "        batch_size=2,\n",
    "        short=False,\n",
    "        temperature=1.,\n",
    "        use_unk=True,\n",
    "        model=model,\n",
    "        data=(x, y),\n",
    "        idx2word=idx2word,\n",
    "        oov0=oov0,\n",
    "        glove_idx2idx=glove_idx2idx,\n",
    "        vocab_size=vocab_size,\n",
    "        nb_unknown_words=nb_unknown_words,\n",
    "    )\n",
    "\n",
    "    headline = samples[0][0][len(samples[0][1]):]\n",
    "    ' '.join(idx2word[w] for w in headline)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sample_str=X_data[5002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 35, 100)           4000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 35, 512)           1255424   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 35, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 35, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 35, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 35, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 35, 512)           0         \n",
      "_________________________________________________________________\n",
      "simplecontext_1 (SimpleConte (None, 10, 944)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 10, 40000)         37800000  \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10, 40000)         0         \n",
      "=================================================================\n",
      "Total params: 47,253,824\n",
      "Trainable params: 47,253,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: an indonesian court on thursday found a man guilty of complicity in a dormitory explosion here last year which killed three acehnese students .\n",
      "HEADS:\n",
      "42.45784819126129 wednesday suspect school two death after sicily\n"
     ]
    }
   ],
   "source": [
    "main(X_data[5002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: australian shares closed down #.# percent monday following a weak lead from the united states and lower commodity prices , dealers said .\n",
      "HEADS:\n",
      "16.101204715669155 australian stocks prices percent percent down\n"
     ]
    }
   ],
   "source": [
    "main(sample_str=X_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "online service helps people cope with aids \n",
      "for richard goldman , the online world is no mere diversion . \n",
      "HEAD: online service helps people cope with aids\n",
      "DESC: for richard goldman , the online world is no mere diversion .\n",
      "HEADS:\n",
      "25.74055814743042 murdoch lynch in is <unk>\n",
      "55.45589569211006 microsoft origin with plans web myspace wit year\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: australian shares closed down #.# percent monday following a weak lead from the united states and lower commodity prices , dealers said .\n",
      "HEADS:\n",
      "6.239161305129528 australian shares close up #.#\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('australian stocks close down #.# percent',\n",
       " 'australian shares closed down #.# percent monday following a weak lead from the united states and lower commodity prices , dealers said .',\n",
       " None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data[1], X_data[1], predict(X_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: new zealand share prices closed #.## percent higher monday in subdued trading ahead of a us holiday , dealers said .\n",
      "HEADS:\n",
      "3.100383333861828 new zealand shares close #.## percent lower\n",
      "16.661406874656677 <unk> zealand shares close #.## #.# higher higher\n"
     ]
    }
   ],
   "source": [
    "predict(X_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new zealand stocks close #.## percent higher'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: thai share prices closed #.## percent lower on thursday amid ongoing concerns over a global economic slowdown , dealers said .\n",
      "HEADS:\n",
      "6.806725982576609 thai shares prices close #.## higher higher\n",
      "23.156850043684244 thai share prices close steady lower firmer concerns\n"
     ]
    }
   ],
   "source": [
    "predict(X_data[43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thai share prices close #.## percent lower'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_list = [100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: south korean shares started more than two percent higher friday as investor sentiment was lifted by overnight gains in us markets .\n",
      "HEADS:\n",
      "24.946189641952515 shanghai stock korean drop on #.# record\n",
      "35.10677613131702 south korean record sharply on markets index percent straight\n",
      "HEAD: <eos>\n",
      "DESC: the european union on wednesday named german diplomat hansjoerg haber to head its observer mission in georgia , a statement said .\n",
      "HEADS:\n",
      "24.87706309556961 eu to chief of visit in cyprus\n",
      "39.1205967162532 eu us visits in november for visit visit counterpart\n",
      "HEAD: <eos>\n",
      "DESC: an apparent suicide attack at the marriott hotel in islamabad killed more than ## people saturday in the latest carnage in pakistan .\n",
      "HEADS:\n",
      "39.479780435562134 teenagers children killed attack afghanistan in shark\n",
      "HEAD: <eos>\n",
      "DESC: german media group prosiebensat .# warned on wednesday it would miss financial targets this year because of the weak television advertising market .\n",
      "HEADS:\n",
      "74.48178877888131 german says firms sainsbury dept. alphabet dc sunbeam win\n",
      "HEAD: <eos>\n",
      "DESC: a new organization was unveiled here monday aimed at promoting nuclear security around the globe so as to prevent terrorists from getting the bomb .\n",
      "HEADS:\n",
      "HEAD: <eos>\n",
      "DESC: riddick bowe punched larry donald at a pre-fight news conference .\n",
      "HEADS:\n",
      "43.870091676712036 tennis dad on crash trainer minus\n",
      "70.91935414075851 revisiting earns holyfield marvin ncaa robbery strife through\n",
      "HEAD: <eos>\n",
      "DESC: the british and french foreign ministers on monday held talks here with croatian president franjo tudjman , diplomats said .\n",
      "HEADS:\n",
      "48.35414370673243 eu italian foreign foreign meet spain npt peace opposition\n",
      "50.60219080961542 french says slovenia in balkan against peace mission ireland\n",
      "HEAD: <eos>\n",
      "DESC: andorra 's parliament wednesday elected ##-year-old lawyer marc forne as new prime minister of the tiny principality .\n",
      "HEADS:\n",
      "42.02919363975525 lithuanian 's d-day interim in interference\n",
      "44.246798515319824 paraguayan championship hong uk step\n",
      "HEAD: <eos>\n",
      "DESC: un bosnia commander lieutenant-general sir michael rose has left sarajevo for the embattled bihac enclave in northwestern bosnia , a un source said saturday .\n",
      "HEADS:\n",
      "HEAD: <eos>\n",
      "DESC: prime minister john major tuesday accused spain of introducing unnecessarily lengthy formalities on its border with the british colony of gibraltar .\n",
      "HEADS:\n",
      "38.31785333156586 prime accuses state-run meat turkish marijuana\n",
      "47.227559208869934 poland denies navy to leaders polar plane\n",
      "HEAD: <eos>\n",
      "DESC: deputies from mozambique 's two major parties were to meet friday in fresh attempts to solve a week-old crisis paralysing the new democratic parliament .\n",
      "HEADS:\n",
      "HEAD: <eos>\n",
      "DESC: the dollar dropped slightly tuesday against major currencies except the japanese yen , with trading calm before the coming holidays .\n",
      "HEADS:\n",
      "14.121852634474635 dollar dollar narrowly\n",
      "17.985646126791835 dollar down against major u.s.\n",
      "HEAD: <eos>\n",
      "DESC: at least eight people were killed in bomb attacks late thursday that destroyed four buses around this caribbean resort city , police said .\n",
      "HEADS:\n",
      "48.27300268411636 rainstorms arrests ## refinery ## boiler indonesia pakistan\n",
      "HEAD: <eos>\n",
      "DESC: france was urged here tuesday to `` revise '' its stand towards algeria after the successful storming of the hijacked air france airbus .\n",
      "HEADS:\n",
      "50.05420243740082 azerbaijan parliament plate over alliances threat\n",
      "HEAD: <eos>\n",
      "DESC: one person was shot dead and half a dozen others wounded when shots were fired at two abortion clinics here friday , police said .\n",
      "HEADS:\n",
      "HEAD: <eos>\n",
      "DESC: saudi security forces shot dead two islamist militants monday in a shootout at the holy city of mecca , state-run channel one television said .\n",
      "HEADS:\n",
      "HEAD: <eos>\n",
      "DESC: telecom 's weakness and an unexpected rate rise in australia dampened the new zealand market wednesday , dealers said .\n",
      "HEADS:\n",
      "49.176413879788015 korda markets markets higher taipei closes stock trading stock\n",
      "49.457487176696304 brazil eu dollar to lower strengthens prices lse exchange\n",
      "HEAD: <eos>\n",
      "DESC: new zealand share prices closed #.## percent higher friday on a rise in casino sky city , dealers said .\n",
      "HEADS:\n",
      "3.768515035510063 new zealand shares close #.##\n",
      "7.852830126881599 new zealand shares close #.## percent up\n",
      "HEAD: <eos>\n",
      "DESC: colombian defense minister martha lucia ramirez resigned sunday , the presidential palace announced in a brief statement .\n",
      "HEADS:\n",
      "17.438050091266632 turkish interior minister resigns confidence\n",
      "24.661986589431763 turkish government quits resigns resigns resigns op\n",
      "HEAD: <eos>\n",
      "DESC: croatia 's former ruling nationalist party called wednesday on all ethnic serb refugees who fled the country during the ####s war to return .\n",
      "HEADS:\n",
      "44.03166198730469 radical war leader with war decide and\n",
      "HEAD: <eos>\n",
      "DESC: a strong earthquake measuring #.# on the richter scale struck southwestern china saturday leaving five people dead and ## injured , state media said .\n",
      "HEADS:\n",
      "HEAD: <eos>\n",
      "DESC: malaysian share prices closed marginally higher tuesday in mixed and volatile trade amid a general lack of leads , dealers said .\n",
      "HEADS:\n",
      "4.271936386823654 malaysian shares close higher\n",
      "14.48050381243229 malaysian shares end down #.#\n",
      "HEAD: <eos>\n",
      "DESC: six schoolchildren were injured in indian-administered kashmir thursday when a hand grenade they fiddled with exploded , a police spokesman said .\n",
      "HEADS:\n",
      "29.388895988464355 five killed in police houses philippines india\n",
      "52.07890963705722 ## bus passenger aceh kills police indonesia slightly violence\n",
      "HEAD: <eos>\n",
      "DESC: cameroon have not lifted an african club trophy for ## years despite being among the leading football nations on the continent .\n",
      "HEADS:\n",
      "35.7291305065155 wembley world miss in ##th in\n",
      "45.734259843826294 czech leaders tough about county match bid\n",
      "HEAD: <eos>\n",
      "DESC: denver broncos coach mike shanahan suspended defensive tackle daryl gardener two additional games tuesday following critical comments on a radio show .\n",
      "HEADS:\n",
      "42.643012046813965 lewis pleads to suspend birthday guzman\n",
      "48.140684366226196 nfl chief reyna workington moss jake\n",
      "HEAD: <eos>\n",
      "DESC: french rugby 's financial watchdog has refused to endorse wales world cup captain colin charvis ' move to second division tarbes .\n",
      "HEADS:\n",
      "36.05080330371857 uefa out on wbc to call-up of\n",
      "49.535952853620984 italy upholds out fa to opening return matches wcup\n",
      "HEAD: <eos>\n",
      "DESC: an average of five us companies a month invested in south africa during #### , the us-based investor responsibility research centre said friday .\n",
      "HEADS:\n",
      "49.18631708621979 manufacturers waiting vs events skorean economy\n",
      "HEAD: <eos>\n",
      "DESC: japanese share prices closed #.# percent lower on tuesday with the nikkei stock average easing on profit-taking .\n",
      "HEADS:\n",
      "9.616662174463272 tokyo share fall #.# percent\n",
      "23.46298184990883 in shares end up percent higher up\n",
      "HEAD: <eos>\n",
      "DESC: a last-minute reprieve thursday saved a ##-year-old man from deportation to nigeria , where he claims his life would be in danger .\n",
      "HEADS:\n",
      "64.4109918475151 need continues illegal clock barcelona on taking ####\n",
      "HEAD: <eos>\n",
      "DESC: a bomb threat forced an air canada jet to make an emergency landing in this newfoundland city , officials said saturday .\n",
      "HEADS:\n",
      "30.824058294296265 philippine ship in railway back after\n",
      "42.62076711654663 repeating sea strikes lands flight plane coast makes\n"
     ]
    }
   ],
   "source": [
    "for i in map(lambda x: x+1, test_list):\n",
    "    try:\n",
    "        predict(X_data[i])\n",
    "    except IndexError:\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skorean shares open sharply higher\n",
      "german diplomat to head eu 's georgia monitoring team\n",
      "major attacks in pakistan in ####\n",
      "german broadcaster prosiebensat .# issues profit warning\n",
      "new institute set up to prevent nuclear theft terrorism\n",
      "bowe weighs in for key fight\n",
      "hurd juppe meet croatian president\n",
      "andorra gets new pm\n",
      "rose heads for embattled bihac enclave\n",
      "major attacks spain over gibraltar border delays\n",
      "search to solve parliamentary crisis\n",
      "dollar drops slightly except against yen gold up\n",
      "eight killed in <unk> bus bombings\n",
      "france urged to revise stand on algeria\n",
      "one dead in new abortion clinic shooting\n",
      "saudi security forces shoot dead two militants in mecca\n",
      "nz stocks fall after telecom results australian rate hike\n",
      "new zealand stocks close #.## percent up\n",
      "colombian defense minister resigns\n",
      "croatian nationalists offer olive branch to serb refugees\n",
      "five dead as strong earthquake hits southwest china\n",
      "malaysian shares close marginally higher\n",
      "six schoolchildren injured in kashmir blast\n",
      "cameroon misery set to continue at club level\n",
      "broncos suspend gardener two more games\n",
      "charvis move to <unk> runs into cash problems\n",
      "us companies targetting south africa\n",
      "tokyo stocks ends #.# percent lower\n",
      "last-minute reprieve saves nigerian from deportation\n",
      "bomb threat on air canada flight forces emergency landing\n"
     ]
    }
   ],
   "source": [
    "for i in map(lambda x: x+1, test_list):\n",
    "    print(Y_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights(FN1_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main(X_data[5002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main(sample_str=X_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights(FN1_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding_1',\n",
       " 'lstm_1',\n",
       " 'dropout_1',\n",
       " 'lstm_2',\n",
       " 'dropout_2',\n",
       " 'lstm_3',\n",
       " 'dropout_3',\n",
       " 'simplecontext_1',\n",
       " 'time_distributed_1',\n",
       " 'activation_1']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " with h5py.File('{}.hdf5'.format(FN1), mode='r') as f:\n",
    "        # new file format\n",
    "        layer_names = [n.decode('utf8') for n in f.attrs['layer_names']]\n",
    "layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(40000, 100, input_length=75, weights=None, mask_zero=True, name=\"embedding_1\", embeddings_regularizer=None)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, return_sequences=True, name=\"lstm_1\", kernel_regularizer=None, bias_regularizer=None, recurrent_regularizer=None, dropout=0, recurrent_dropout=0)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, return_sequences=True, name=\"lstm_2\", kernel_regularizer=None, bias_regularizer=None, recurrent_regularizer=None, dropout=0, recurrent_dropout=0)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, return_sequences=True, name=\"lstm_3\", kernel_regularizer=None, bias_regularizer=None, recurrent_regularizer=None, dropout=0, recurrent_dropout=0)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(40000, name=\"timedistributed_1\", kernel_regularizer=None, bias_regularizer=None)`\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bf0bc20aec2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}.hdf5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFN1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_weights'"
     ]
    }
   ],
   "source": [
    " # load model parameters used for training\n",
    "with open('model_params.json', 'r') as f:\n",
    "    model_params = json.load(f)\n",
    "\n",
    "# create placeholder model\n",
    "model = create_model(**model_params)\n",
    "\n",
    "model.load_weights('{}.hdf5'.format(FN1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-189cec088472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_params.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "with open('model_params.json', 'r') as f:\n",
    "    model_params = json.load(f)\n",
    "print(model_params.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: SimpleContext",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-96d2e4a86c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'summ_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    315\u001b[0m                         \u001b[0;34m'Maybe you meant to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 return cls.from_config(config['config'],\n\u001b[1;32m    143\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 144\u001b[0;31m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 138\u001b[0;31m                                  ': ' + class_name)\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: SimpleContext"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('summ_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of embedding space for words: 100\n",
      "vocabulary size: 40,000 the last 10 words can be used as place holders for unknown/oov words\n",
      "total number of different words: 90,818\n",
      "number of words outside vocabulary which we can substitue using glove similarity: 32,532\n",
      "number of words that will be regarded as unknonw(unk)/out-of-vocabulary(oov): 18,286\n",
      "number of examples 500000 500000\n",
      "Random head, description:\n",
      "H: un chief condemns somalia suicide blast\n",
      "\n",
      "D: un chief ban ki-moon thursday denounced a suicide attack on a somali graduation ceremony which left ## people dead including three government ministers .\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(40000, 100, input_length=35, weights=[array([[-..., mask_zero=True, name=\"embedding_1\", embeddings_regularizer=None)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, return_sequences=True, name=\"lstm_1\", kernel_regularizer=None, bias_regularizer=None, recurrent_regularizer=None, dropout=0, recurrent_dropout=0)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, return_sequences=True, name=\"lstm_2\", kernel_regularizer=None, bias_regularizer=None, recurrent_regularizer=None, dropout=0, recurrent_dropout=0)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, return_sequences=True, name=\"lstm_3\", kernel_regularizer=None, bias_regularizer=None, recurrent_regularizer=None, dropout=0, recurrent_dropout=0)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(40000, name=\"time_distributed_2\", kernel_regularizer=None, bias_regularizer=None)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cls=Embedding name=embedding_1\n",
      "40000x100 \n",
      "\n",
      "1 cls=LSTM name=lstm_1\n",
      "100x2048 512x2048 2048 \n",
      "\n",
      "2 cls=Dropout name=dropout_1\n",
      "\n",
      "\n",
      "3 cls=LSTM name=lstm_2\n",
      "512x2048 512x2048 2048 \n",
      "\n",
      "4 cls=Dropout name=dropout_2\n",
      "\n",
      "\n",
      "5 cls=LSTM name=lstm_3\n",
      "512x2048 512x2048 2048 \n",
      "\n",
      "6 cls=Dropout name=dropout_3\n",
      "\n",
      "\n",
      "7 cls=SimpleContext name=simplecontext_1\n",
      "\n",
      "\n",
      "8 cls=TimeDistributed name=time_distributed_3\n",
      "944x40000 40000 \n",
      "\n",
      "9 cls=Activation name=activation_1\n",
      "\n",
      "\n",
      "Model weights loaded from train.hdf5\n",
      "HEAD: obama clinton pledge us support for aids fight\n",
      "DESC: president barack obama and secretary of state hillary rodham clinton have pledged the support of the united states in the global fight against aids .\n",
      "HEADS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1038s 2s/step - loss: 5.1777 - val_loss: 5.4930\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1035s 2s/step - loss: 5.2472 - val_loss: 5.4923\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1037s 2s/step - loss: 5.2135 - val_loss: 5.4688\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1038s 2s/step - loss: 5.1904 - val_loss: 5.4441\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1034s 2s/step - loss: 5.1671 - val_loss: 5.4198\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1035s 2s/step - loss: 5.1330 - val_loss: 5.3971\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 1036s 2s/step - loss: 5.1079 - val_loss: 5.3797\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 1033s 2s/step - loss: 5.0898 - val_loss: 5.3423\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 1033s 2s/step - loss: 5.0441 - val_loss: 5.3434\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 1033s 2s/step - loss: 5.0199 - val_loss: 5.3114\n",
      "HEAD: policewomen^ hit the streets in iran\n",
      "DESC: more than ### women graduated from iran 's female police academy saturday , the second only such graduation since the #### islamic revolution .\n",
      "HEADS:\n",
      "15.356314539909363 thousands of women in\n",
      "15.419548034667969 human students of of\n",
      "19.10608172416687 human students of of of in\n",
      "19.281599760055542 human students of of in of\n",
      "21.280718564987183 human students of of in at\n",
      "21.68861758708954 human students of of of of of\n",
      "21.793751001358032 human students of of in of of\n",
      "24.87529683113098 human students of of in of of in\n",
      "25.2915181517601 human students of of in of of anniversary\n",
      "26.648081183433533 human students of of of of of us\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Train a sequence to sequence model.\n",
    "\n",
    "This script is sourced from Siraj Rival\n",
    "https://github.com/llSourcell/How_to_make_a_text_summarizer/blob/master/train.ipynb\n",
    "\"\"\"\n",
    "\n",
    "epochs=10\n",
    "rnn_size=512\n",
    "rnn_layers=3\n",
    "nsamples=640\n",
    "nflips=0\n",
    "temperature=.8\n",
    "lr=0.0001\n",
    "warm_start='store_true'\n",
    "batch_size=32\n",
    "\n",
    "# set sample sizes\n",
    "nb_train_samples = np.int(np.floor(nsamples / batch_size)) * batch_size  # num training samples\n",
    "nb_val_samples = nb_train_samples  # num validation samples\n",
    "\n",
    "# seed weight initialization\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "embedding, idx2word, word2idx, glove_idx2idx = load_embedding(nb_unknown_words)\n",
    "vocab_size, embedding_size = embedding.shape\n",
    "oov0 = vocab_size - nb_unknown_words\n",
    "idx2word = process_vocab(idx2word, vocab_size, oov0, nb_unknown_words)\n",
    "X_train, X_test, Y_train, Y_test = load_split_data(nb_val_samples, seed)\n",
    "\n",
    "# print a sample recipe to make sure everything looks right\n",
    "print('Random head, description:')\n",
    "i = 811\n",
    "prt('H', Y_train[i], idx2word)\n",
    "prt('D', X_train[i], idx2word)\n",
    "\n",
    "# save model initialization parameters\n",
    "model_params = (dict(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=embedding_size,\n",
    "    LR=lr,\n",
    "    rnn_layers=rnn_layers,\n",
    "    rnn_size=rnn_size,\n",
    "))\n",
    "with open('model_params.json', 'w') as f:\n",
    "    json.dump(model_params, f)\n",
    "\n",
    "\n",
    "model = create_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=embedding_size,\n",
    "    LR=lr,\n",
    "    embedding=embedding,\n",
    "    rnn_layers=rnn_layers,\n",
    "    rnn_size=rnn_size,\n",
    ")\n",
    "inspect_model(model)\n",
    "\n",
    "# load pre-trained model weights\n",
    "FN1_filename = '{}.hdf5'.format(FN1)\n",
    "if warm_start and FN1 and os.path.exists(FN1_filename):\n",
    "    model.load_weights(FN1_filename)\n",
    "    print('Model weights loaded from {}'.format(FN1_filename))\n",
    "\n",
    "# print samples before training\n",
    "gensamples(\n",
    "    skips=2,\n",
    "    k=10,\n",
    "    batch_size=batch_size,\n",
    "    short=False,\n",
    "    temperature=temperature,\n",
    "    use_unk=True,\n",
    "    model=model,\n",
    "    data=(X_test, Y_test),\n",
    "    idx2word=idx2word,\n",
    "    oov0=oov0,\n",
    "    glove_idx2idx=glove_idx2idx,\n",
    "    vocab_size=vocab_size,\n",
    "    nb_unknown_words=nb_unknown_words,\n",
    ")\n",
    "\n",
    "# get train and validation generators\n",
    "r = next(gen(X_train, Y_train, batch_size=batch_size, nb_batches=None, nflips=None, model=None, debug=False, oov0=oov0, glove_idx2idx=glove_idx2idx, vocab_size=vocab_size, nb_unknown_words=nb_unknown_words, idx2word=idx2word))\n",
    "traingen = gen(X_train, Y_train, batch_size=batch_size, nb_batches=None, nflips=nflips, model=model, debug=False, oov0=oov0, glove_idx2idx=glove_idx2idx, vocab_size=vocab_size, nb_unknown_words=nb_unknown_words, idx2word=idx2word)\n",
    "valgen = gen(X_test, Y_test, batch_size=batch_size, nb_batches=nb_val_samples // batch_size, nflips=None, model=None, debug=False, oov0=oov0, glove_idx2idx=glove_idx2idx, vocab_size=vocab_size, nb_unknown_words=nb_unknown_words, idx2word=idx2word)\n",
    "\n",
    "# define callbacks for training\n",
    "callbacks = [TensorBoard(\n",
    "    log_dir=str(time.time()),\n",
    "    histogram_freq=0, write_graph=False, write_images=False)]\n",
    "\n",
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "model.save('summ_model.h5')\n",
    "\n",
    "model.save_weights('train1.hdf5', overwrite=True)\n",
    "\n",
    "# print samples after training\n",
    "samples = gensamples(\n",
    "    skips=2,\n",
    "    k=10,\n",
    "    batch_size=batch_size,\n",
    "    short=False,\n",
    "    temperature=temperature,\n",
    "    use_unk=True,\n",
    "    model=model,\n",
    "    data=(X_test, Y_test),\n",
    "    idx2word=idx2word,\n",
    "    oov0=oov0,\n",
    "    glove_idx2idx=glove_idx2idx,\n",
    "    vocab_size=vocab_size,\n",
    "    nb_unknown_words=nb_unknown_words,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1038s 2s/step - loss: 4.9934 - val_loss: 5.2885\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1039s 2s/step - loss: 4.9645 - val_loss: 5.2363\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1037s 2s/step - loss: 4.9069 - val_loss: 5.2039\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1047s 2s/step - loss: 4.8646 - val_loss: 5.1527\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1060s 2s/step - loss: 4.8095 - val_loss: 5.1178\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1045s 2s/step - loss: 4.7676 - val_loss: 5.0791\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 1048s 2s/step - loss: 4.7352 - val_loss: 5.0421\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 1047s 2s/step - loss: 4.7155 - val_loss: 5.0190\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 1064s 2s/step - loss: 4.6808 - val_loss: 4.9884\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 1055s 2s/step - loss: 4.6400 - val_loss: 4.9884\n"
     ]
    }
   ],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights('train1.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1104s 2s/step - loss: 4.7578 - val_loss: 4.9401\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1205s 2s/step - loss: 4.7269 - val_loss: 4.9198\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1184s 2s/step - loss: 4.6858 - val_loss: 4.8947\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1186s 2s/step - loss: 4.6847 - val_loss: 4.8717\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1186s 2s/step - loss: 4.6530 - val_loss: 4.8656\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1184s 2s/step - loss: 4.6256 - val_loss: 4.8391\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 1186s 2s/step - loss: 4.6326 - val_loss: 4.8208\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 1187s 2s/step - loss: 4.5905 - val_loss: 4.7928\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 1191s 2s/step - loss: 4.5841 - val_loss: 4.7898\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 1187s 2s/step - loss: 4.5424 - val_loss: 4.7762\n"
     ]
    }
   ],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights('train1.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1188s 2s/step - loss: 4.5007 - val_loss: 4.7529\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1188s 2s/step - loss: 4.4983 - val_loss: 4.7405\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1190s 2s/step - loss: 4.4833 - val_loss: 4.7407\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1191s 2s/step - loss: 4.4444 - val_loss: 4.7091\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1190s 2s/step - loss: 4.4574 - val_loss: 4.7123\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1193s 2s/step - loss: 4.4112 - val_loss: 4.6832\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 1199s 2s/step - loss: 4.3971 - val_loss: 4.6485\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 1226s 2s/step - loss: 4.3748 - val_loss: 4.6466\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 1230s 2s/step - loss: 4.3485 - val_loss: 4.6256\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 1209s 2s/step - loss: 4.3377 - val_loss: 4.6312\n"
     ]
    }
   ],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights('train1.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1215s 2s/step - loss: 4.3383 - val_loss: 4.6207\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1203s 2s/step - loss: 4.3453 - val_loss: 4.6015\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1210s 2s/step - loss: 4.2716 - val_loss: 4.5812\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1196s 2s/step - loss: 4.2745 - val_loss: 4.5700\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1206s 2s/step - loss: 4.2652 - val_loss: 4.5508\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1206s 2s/step - loss: 4.2604 - val_loss: 4.5334\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 1189s 2s/step - loss: 4.2258 - val_loss: 4.5414\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 1192s 2s/step - loss: 4.2095 - val_loss: 4.5336\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 1191s 2s/step - loss: 4.1975 - val_loss: 4.5119\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 1193s 2s/step - loss: 4.1788 - val_loss: 4.5017\n"
     ]
    }
   ],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights('train1.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "main() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e7a0eb0f02c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: main() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "main(X_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict(X_data[5002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1052s 2s/step - loss: 4.1742 - val_loss: 4.4962\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1160s 2s/step - loss: 4.1615 - val_loss: 4.4716\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1172s 2s/step - loss: 4.1308 - val_loss: 4.4639\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1176s 2s/step - loss: 4.1170 - val_loss: 4.4503\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1183s 2s/step - loss: 4.1274 - val_loss: 4.4332\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1169s 2s/step - loss: 4.1041 - val_loss: 4.4221\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 1174s 2s/step - loss: 4.0789 - val_loss: 4.4130\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 1166s 2s/step - loss: 4.0861 - val_loss: 4.3863\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 1170s 2s/step - loss: 4.0646 - val_loss: 4.3799\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 1169s 2s/step - loss: 4.0375 - val_loss: 4.3831\n"
     ]
    }
   ],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights('train1.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1177s 2s/step - loss: 4.0556 - val_loss: 4.3812\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1171s 2s/step - loss: 4.0132 - val_loss: 4.3741\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1162s 2s/step - loss: 3.9916 - val_loss: 4.3666\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 1149s 2s/step - loss: 3.9971 - val_loss: 4.3549\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 1148s 2s/step - loss: 3.9690 - val_loss: 4.3443\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 1151s 2s/step - loss: 3.9393 - val_loss: 4.3270\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 1148s 2s/step - loss: 3.9626 - val_loss: 4.3334\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 1142s 2s/step - loss: 3.9287 - val_loss: 4.3126\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 1140s 2s/step - loss: 3.9117 - val_loss: 4.2952\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 1140s 2s/step - loss: 3.9296 - val_loss: 4.2901\n"
     ]
    }
   ],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights('train1.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=640, epochs=10, validation_steps=640)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 1137s 2s/step - loss: 3.9309 - val_loss: 4.2731\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 1143s 2s/step - loss: 3.8750 - val_loss: 4.2736\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 1156s 2s/step - loss: 3.8973 - val_loss: 4.2813\n",
      "Epoch 4/10\n",
      " 22/640 [>.............................] - ETA: 14:56 - loss: 3.8397"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ed3fe2792758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_val_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#nb_epoch=1, validation_data=valgen, nb_val_samples=1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1276\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights('train1.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'indonesian court jails acehnese man over jakarta dormitory blast'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data[5002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: an indonesian court on thursday found a man guilty of complicity in a dormitory explosion here last year which killed three acehnese students .\n",
      "HEADS:\n",
      "45.24977836459584 indonesian president admits iranian man over southwest mosque workington\n"
     ]
    }
   ],
   "source": [
    "main(X_data[5002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'australian stocks close down #.# percent'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: australian shares closed down #.# percent monday following a weak lead from the united states and lower commodity prices , dealers said .\n",
      "HEADS:\n",
      "1.0864221453666687 australian shares close down #.# percent\n"
     ]
    }
   ],
   "source": [
    "main(X_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new zealand stocks close #.## percent higher'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: new zealand share prices closed #.## percent higher monday in subdued trading ahead of a us holiday , dealers said .\n",
      "HEADS:\n",
      "1.2584268148057163 new zealand shares close #.## percent higher\n",
      "1.2584268148057163 new zealand shares close #.## percent higher\n"
     ]
    }
   ],
   "source": [
    "main(X_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stockholm stock exchange plummets more than five percent'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data[502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: the stockholm stock exchange plunged #.## percent in late afternoon trading monday , amid continued anxiety over the global banking sector crisis .\n",
      "HEADS:\n",
      "18.302044562995434 nyse 's financial exchange falls #.## percent\n"
     ]
    }
   ],
   "source": [
    "main(X_data[502])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"stuttgart 's bordon out until ####\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_data[1572]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD: <eos>\n",
      "DESC: german bundesliga side vfb stuttgart must do without the <unk> of key brazilian defender marcelo bordon until the new year .\n",
      "HEADS:\n",
      "17.951275780797005 bremen retires against brazilian bundesliga\n",
      "39.79736316204071 german toro teenager drops <unk> achilles\n"
     ]
    }
   ],
   "source": [
    "main(X_data[1572])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "german inflation set to slow in january \n",
      "inflation in germany , the eurozone 's biggest economy , looked set to slow this month , key regional data showed on monday . \n",
      "HEAD: german inflation set to slow in january\n",
      "DESC: inflation in germany , the eurozone 's biggest economy , looked set to slow this month , key regional data showed on monday .\n",
      "HEADS:\n",
      "9.989503264427185 german inflation slows #.#\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "broncos marvel at elway 's talents \n",
      "for denver tight end shannon sharpe , quarterback john elway was like halley 's comet . \n",
      "HEAD: broncos marvel at elway 's talents\n",
      "DESC: for denver tight end shannon sharpe , quarterback john elway was like halley 's comet .\n",
      "HEADS:\n",
      "28.652511835098267 cowboys lauds faith for death\n",
      "47.293256998062134 qb s feelings and his mourning waiting for\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly sampled recipe:\n",
      "palestinian authority issues license plates in gaza \n",
      "the palestinian authority in the gaza strip issued its first license plates to residents wednesday , asserting one of its rights under autonomy . \n",
      "HEAD: palestinian authority issues license plates in gaza\n",
      "DESC: the palestinian authority in the gaza strip issued its first license plates to residents wednesday , asserting one of its rights under autonomy .\n",
      "HEADS:\n",
      "40.15202474594116 palestinians say equipment 's gaza licenses of americans\n"
     ]
    }
   ],
   "source": [
    "main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model and save weights\n",
    "h = model.fit_generator(\n",
    "    traingen, samples_per_epoch=nb_train_samples,\n",
    "    #traingen, samples_per_epoch=3,\n",
    "    nb_epoch=epochs, validation_data=valgen, nb_val_samples=nb_val_samples,\n",
    "    #nb_epoch=1, validation_data=valgen, nb_val_samples=1,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.save_weights('train1.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [7.7715, \n",
    "  7.3500, \n",
    "  7.0481, \n",
    "  6.8892, \n",
    "  6.7359, \n",
    "  6.5877, \n",
    "  6.4747, \n",
    "  6.3919, \n",
    "  6.3057, \n",
    "  6.2325, \n",
    "  6.1753, \n",
    "  6.1332, \n",
    "  6.0746, \n",
    "  6.0262, \n",
    "  5.9716, \n",
    "  5.9246, \n",
    "  5.8926, \n",
    "  5.8604, \n",
    "  5.8247, \n",
    "  5.7850, \n",
    "  5.6642, \n",
    "  5.6829, \n",
    "  5.6340, \n",
    "  5.6087, \n",
    "  5.5869, \n",
    "  5.5568, \n",
    "  5.5303, \n",
    "  5.5137, \n",
    "  5.4644, \n",
    "  5.4420, \n",
    "  5.4146, \n",
    "  5.4007, \n",
    "  5.3649, \n",
    "  5.3384, \n",
    "  5.2994, \n",
    "  5.2729, \n",
    "  5.2575, \n",
    "  5.2429, \n",
    "  5.2223, \n",
    "  5.1901, \n",
    "  5.1777, \n",
    "  5.2472, \n",
    "  5.2135, \n",
    "  5.1904, \n",
    "  5.1671, \n",
    "  5.1330, \n",
    "  5.1079, \n",
    "  5.0898, \n",
    "  5.0441, \n",
    "  5.0199, \n",
    "  4.9934, \n",
    "  4.9645, \n",
    "  4.9069, \n",
    "  4.8646, \n",
    "  4.8095, \n",
    "  4.7676, \n",
    "  4.7352, \n",
    "  4.7155, \n",
    "  4.6808, \n",
    "  4.6400, \n",
    "  4.7578, \n",
    "  4.7269, \n",
    "  4.6858, \n",
    "  4.6847, \n",
    "  4.6530, \n",
    "  4.6256, \n",
    "  4.6326, \n",
    "  4.5905, \n",
    "  4.5841, \n",
    "  4.5424, \n",
    "  4.5007, \n",
    "  4.4983, \n",
    "  4.4833, \n",
    "  4.4444, \n",
    "  4.4574, \n",
    "  4.4112, \n",
    "  4.3971, \n",
    "  4.3748, \n",
    "  4.3485, \n",
    "  4.3377, \n",
    "  4.3383, \n",
    "  4.3453, \n",
    "  4.2716, \n",
    "  4.2745, \n",
    "  4.2652, \n",
    "  4.2604, \n",
    "  4.2258, \n",
    "  4.2095, \n",
    "  4.1975, \n",
    "  4.1788, \n",
    "  4.1742, \n",
    "  4.1615, \n",
    "  4.1308, \n",
    "  4.1170, \n",
    "  4.1274, \n",
    "  4.1041, \n",
    "  4.0789, \n",
    "  4.0861, \n",
    "  4.0646, \n",
    "  4.0375, \n",
    "  4.0556, \n",
    "  4.0132, \n",
    "  3.9916, \n",
    "  3.9971, \n",
    "  3.9690, \n",
    "  3.9393, \n",
    "  3.9626, \n",
    "  3.9287, \n",
    "  3.9117, \n",
    "  3.9296]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_list = [7.5011,\n",
    "7.1762,\n",
    "6.9895,\n",
    "6.8327,\n",
    "6.6672,\n",
    "6.5413,\n",
    "6.4282,\n",
    "6.3386,\n",
    "6.2819,\n",
    "6.2114,\n",
    "6.1589,\n",
    "6.1029,\n",
    "6.0598,\n",
    "6.0143,\n",
    "5.9640,\n",
    "5.9356,\n",
    "5.9018,\n",
    "5.8788,\n",
    "5.8510,\n",
    "5.8220,\n",
    "5.8062,\n",
    "5.7766,\n",
    "5.7428,\n",
    "5.7224,\n",
    "5.6892,\n",
    "5.6771,\n",
    "5.6525,\n",
    "5.6334,\n",
    "5.6266,\n",
    "5.5974,\n",
    "5.5801,\n",
    "5.5484,\n",
    "5.5254,\n",
    "5.5066,\n",
    "5.4803,\n",
    "5.4642,\n",
    "5.4531,\n",
    "5.4500,\n",
    "5.4322,\n",
    "5.4286,\n",
    "5.4930,\n",
    "5.4923,\n",
    "5.4688,\n",
    "5.4441,\n",
    "5.4198,\n",
    "5.3971,\n",
    "5.3797,\n",
    "5.3423,\n",
    "5.3434,\n",
    "5.3114,\n",
    "5.2885,\n",
    "5.2363,\n",
    "5.2039,\n",
    "5.1527,\n",
    "5.1178,\n",
    "5.0791,\n",
    "5.0421,\n",
    "5.0190,\n",
    "4.9884,\n",
    "4.9884,\n",
    "4.9401,\n",
    "4.9198,\n",
    "4.8947,\n",
    "4.8717,\n",
    "4.8656,\n",
    "4.8391,\n",
    "4.8208,\n",
    "4.7928,\n",
    "4.7898,\n",
    "4.7762,\n",
    "4.7529,\n",
    "4.7405,\n",
    "4.7407,\n",
    "4.7091,\n",
    "4.7123,\n",
    "4.6832,\n",
    "4.6485,\n",
    "4.6466,\n",
    "4.6256,\n",
    "4.6312,\n",
    "4.6207,\n",
    "4.6015,\n",
    "4.5812,\n",
    "4.5700,\n",
    "4.5508,\n",
    "4.5334,\n",
    "4.5414,\n",
    "4.5336,\n",
    "4.5119,\n",
    "4.5017,\n",
    "4.4962,\n",
    "4.4716,\n",
    "4.4639,\n",
    "4.4503,\n",
    "4.4332,\n",
    "4.4221,\n",
    "4.4130,\n",
    "4.3863,\n",
    "4.3799,\n",
    "4.3831,\n",
    "4.3812,\n",
    "4.3741,\n",
    "4.3666,\n",
    "4.3549,\n",
    "4.3443,\n",
    "4.3270,\n",
    "4.3334,\n",
    "4.3126,\n",
    "4.2952,\n",
    "4.2901]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 110)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_list), len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e5e2285eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(110), train_list, label = 'Training Loss')\n",
    "plt.plot(range(110), val_list, label = 'Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
